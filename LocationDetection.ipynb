{"cells":[{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2623,"status":"ok","timestamp":1673894818883,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"7RXsiuHwh3XW","outputId":"0279f373-348b-4f49-81ed-5352f7e3ee7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"txXGCTY2kNqz"},"source":["Sources: \n","- https://github.com/CSAILVision/places365\n","- https://colab.research.google.com/drive/1iGGrigHMoCFcaneMb6g4Zqh5iZEMMuye#scrollTo=xRrZdXAqfy0X "]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1673894818884,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"Wv1WSPCWkSTs"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable as V\n","import torchvision.models as models\n","from torchvision import transforms as trn\n","from torch.nn import functional as F\n","import os\n","import numpy as np\n","import cv2\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","import pandas as pd\n","import csv"]},{"cell_type":"code","execution_count":107,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1673894818885,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"-ZSFdzjPkZYz"},"outputs":[],"source":[" # hacky way to deal with the Pytorch 1.0 update\n","def recursion_change_bn(module):\n","    if isinstance(module, torch.nn.BatchNorm2d):\n","        module.track_running_stats = 1\n","    else:\n","        for i, (name, module1) in enumerate(module._modules.items()):\n","            module1 = recursion_change_bn(module1)\n","    return module\n"]},{"cell_type":"code","execution_count":108,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1673894818887,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"9iaNHeGpkdjL"},"outputs":[],"source":["\n","def load_labels():\n","    # prepare all the labels\n","    # scene category relevant\n","    file_name_category = 'categories_places365.txt'\n","    if not os.access(file_name_category, os.W_OK):\n","        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n","        os.system('wget ' + synset_url)\n","    classes = list()\n","    with open(file_name_category) as class_file:\n","        for line in class_file:\n","            classes.append(line.strip().split(' ')[0][3:])\n","    classes = tuple(classes)\n","\n","    # indoor and outdoor relevant\n","    file_name_IO = 'IO_places365.txt'\n","    if not os.access(file_name_IO, os.W_OK):\n","        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/IO_places365.txt'\n","        os.system('wget ' + synset_url)\n","    with open(file_name_IO) as f:\n","        lines = f.readlines()\n","        labels_IO = []\n","        for line in lines:\n","            items = line.rstrip().split()\n","            labels_IO.append(int(items[-1]) -1) # 0 is indoor, 1 is outdoor\n","    labels_IO = np.array(labels_IO)\n","\n","    # scene attribute relevant\n","    file_name_attribute = 'labels_sunattribute.txt'\n","    if not os.access(file_name_attribute, os.W_OK):\n","        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n","        os.system('wget ' + synset_url)\n","    with open(file_name_attribute) as f:\n","        lines = f.readlines()\n","        labels_attribute = [item.rstrip() for item in lines]\n","    file_name_W = 'W_sceneattribute_wideresnet18.npy'\n","    if not os.access(file_name_W, os.W_OK):\n","        synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n","        os.system('wget ' + synset_url)\n","    W_attribute = np.load(file_name_W)\n","\n","    return classes, labels_IO, labels_attribute, W_attribute"]},{"cell_type":"code","execution_count":109,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673894818888,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"G2NEm-wdkggp"},"outputs":[],"source":["def hook_feature(module, input, output):\n","    features_blobs.append(np.squeeze(output.data.cpu().numpy()))"]},{"cell_type":"code","execution_count":110,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1673894818889,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"p9gPeKTnkhYY"},"outputs":[],"source":["def returnCAM(feature_conv, weight_softmax, class_idx):\n","    # generate the class activation maps upsample to 256x256\n","    size_upsample = (256, 256)\n","    nc, h, w = feature_conv.shape\n","    output_cam = []\n","    for idx in class_idx:\n","        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n","        cam = cam.reshape(h, w)\n","        cam = cam - np.min(cam)\n","        cam_img = cam / np.max(cam)\n","        cam_img = np.uint8(255 * cam_img)\n","        output_cam.append(cv2.resize(cam_img, size_upsample))\n","    return output_cam"]},{"cell_type":"code","execution_count":111,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673894818890,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"N7Ak6Np4kls4"},"outputs":[],"source":["def returnTF():\n","# load the image transformer\n","    tf = trn.Compose([\n","        trn.Resize((224,224)),\n","        trn.ToTensor(),\n","        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    return tf"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1673894818890,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"qpyEkHTzkprG"},"outputs":[],"source":["def load_model():\n","    # this model has a last conv feature map as 14x14\n","\n","    model_file = 'wideresnet18_places365.pth.tar'\n","    if not os.access(model_file, os.W_OK):\n","        os.system('wget http://places2.csail.mit.edu/models_places365/' + model_file)\n","        os.system('wget https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py')\n","\n","    import wideresnet\n","    model = wideresnet.resnet18(num_classes=365)\n","    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n","    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n","    model.load_state_dict(state_dict)\n","    \n","    # hacky way to deal with the upgraded batchnorm2D and avgpool layers...\n","    for i, (name, module) in enumerate(model._modules.items()):\n","        module = recursion_change_bn(model)\n","    model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n","    \n","    model.eval()\n","\n","\n","\n","    # the following is deprecated, everything is migrated to python36\n","\n","    ## if you encounter the UnicodeDecodeError when use python3 to load the model, add the following line will fix it. Thanks to @soravux\n","    #from functools import partial\n","    #import pickle\n","    #pickle.load = partial(pickle.load, encoding=\"latin1\")\n","    #pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")\n","    #model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle)\n","\n","    model.eval()\n","    # hook the feature extractor\n","    features_names = ['layer4','avgpool'] # this is the last conv layer of the resnet\n","    for name in features_names:\n","        model._modules.get(name).register_forward_hook(hook_feature)\n","    return model"]},{"cell_type":"code","execution_count":113,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1673894818890,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"mpVM4IvbktFK"},"outputs":[],"source":["# load the labels\n","classes, labels_IO, labels_attribute, W_attribute = load_labels()"]},{"cell_type":"code","execution_count":114,"metadata":{"executionInfo":{"elapsed":407,"status":"ok","timestamp":1673894819284,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"DFR5uaLykvFY"},"outputs":[],"source":["# load the model\n","features_blobs = []\n","model = load_model()"]},{"cell_type":"code","execution_count":115,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673894819285,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"sjgyFdu3kw02"},"outputs":[],"source":["# load the transformer\n","tf = returnTF() # image transformer"]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673894819286,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"rpz1wGrQkzPE"},"outputs":[],"source":["# get the softmax weight\n","params = list(model.parameters())\n","weight_softmax = params[-2].data.numpy()\n","weight_softmax[weight_softmax<0] = 0"]},{"cell_type":"code","execution_count":127,"metadata":{"executionInfo":{"elapsed":16021,"status":"ok","timestamp":1673895650881,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"8ZI34nlnppmp"},"outputs":[],"source":["directory = os.fsencode(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\")\n","\n","frame_names = []\n","io_score = []\n","io = []\n","prob_cat_1 = []\n","cat_1 = []\n","prob_cat_2 = []\n","cat_2 = []\n","prob_cat_3 = []\n","cat_3 = []\n","prob_cat_4 = []\n","cat_4 = []\n","prob_cat_5 = []\n","cat_5 = []\n","\n","for file in os.listdir(directory):\n","\n","    filename = os.fsdecode(file)\n","\n","    frame_names.append(filename)\n","\n","    img = Image.open(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\" + filename)\n","    input_img = V(tf(img).unsqueeze(0))   \n","    logit = model.forward(input_img)\n","    h_x = F.softmax(logit, 1).data.squeeze()\n","    probs, idx = h_x.sort(0, True)\n","    probs = probs.numpy()\n","    idx = idx.numpy() \n","\n","    io_image = np.mean(labels_IO[idx[:10]])\n","    io_score.append(io_image)\n","    if io_image < 0.5:\n","      io.append(\"indoor\")\n","    else:\n","      io.append(\"outdoor\")\n","    \n","    prob_cat_1.append(probs[0])\n","    cat_1.append(classes[idx[0]])\n","    prob_cat_2.append(probs[1])\n","    cat_2.append(classes[idx[1]])\n","    prob_cat_3.append(probs[2])\n","    cat_3.append(classes[idx[2]])\n","    prob_cat_4.append(probs[3])\n","    cat_4.append(classes[idx[3]])\n","    prob_cat_5.append(probs[4])\n","    cat_5.append(classes[idx[4]])\n","\n","    img = cv2.imread(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\" + filename)\n","    loc1 = \"Location 1: {} ({})\". format(cat_1[len(cat_1)-1], \"{:.2f}\".format(prob_cat_1[len(prob_cat_1)-1]))\n","    loc2 = \"Location 2: {} ({})\". format(cat_2[len(cat_2)-1], \"{:.2f}\".format(prob_cat_2[len(prob_cat_2)-1]))\n","    loc3 = \"Location 3: {} ({})\". format(cat_3[len(cat_3)-1], \"{:.2f}\".format(prob_cat_3[len(prob_cat_3)-1]))\n","    cat = \"Category: {}\".format(io[len(io)-1])\n","\n","    color = (255,255,255)\n","    cv2.putText(img, loc1, (20, 40), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n","    cv2.putText(img, loc2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n","    cv2.putText(img, loc3, (20, 80), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n","    cv2.putText(img, cat, (20, 110), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n","\n","    cv2.imwrite(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Location/Siedler/\" + filename, img)"]},{"cell_type":"code","execution_count":118,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1673894822985,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"Pv0jS-x3v-ik"},"outputs":[],"source":["df = pd.DataFrame(list(zip(frame_names, io_score, io, prob_cat_1, cat_1, prob_cat_2, cat_2, prob_cat_3, cat_3, prob_cat_4, cat_4, prob_cat_5, cat_5)))\n","df.columns = ['Name', 'io_score', 'io', 'prob_cat_1', 'cat_1', 'prob_cat_2', 'cat_2', 'prob_cat_3', 'cat_3', 'prob_cat_4', 'cat_4', 'prob_cat_5', 'cat_5']\n","df.to_csv(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Location/siedler_location.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPegP8L6PGo6/i3EImAcF94","provenance":[]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.9 (main, Dec 15 2022, 18:18:30) [Clang 14.0.0 (clang-1400.0.29.202)]"},"vscode":{"interpreter":{"hash":"b84c6385a660d7f75b973b812e8733d5edf6dc187bff937f407889d8571426b1"}}},"nbformat":4,"nbformat_minor":0}
