{"cells":[{"cell_type":"markdown","metadata":{"id":"GfmGhl_haAW5"},"source":["Source: https://dev.to/ethand91/simple-age-and-gender-detection-using-python-and-opencv-319h\n","\n","https://github.com/smahesh29/Gender-and-Age-Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1401,"status":"ok","timestamp":1675001613642,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"giUgbxnj4CPf","outputId":"d1c5ba20-21e4-4214-8a99-df75337759a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement agegender_estimation (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for agegender_estimation\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#!pip install agegender_estimation"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":455,"status":"ok","timestamp":1675947808996,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"UlA88glLPIx1"},"outputs":[],"source":["import numpy as np\n","import os, cv2\n","from google.colab.patches import cv2_imshow\n","import pandas as pd\n","import math\n","import sys\n","#from agegender_estimation import AgeGenderEstimation"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1675947813901,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"GXvIwqgnSQ1Z","outputId":"4cbf4324-fbbc-4efa-ae77-335f45b6269b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675947815564,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"jV3ZSe-ehvFE","outputId":"f968a245-d93a-4af6-ae31-6898bf8025d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Gender-and-Age-Detection' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/smahesh29/Gender-and-Age-Detection.git"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":642,"status":"ok","timestamp":1675947819239,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"OU3eAVpTZ_Ky"},"outputs":[],"source":["# Defined the model files\n","FACE_PROTO = \"/content/Gender-and-Age-Detection/opencv_face_detector.pbtxt\"\n","FACE_MODEL = \"/content/Gender-and-Age-Detection/opencv_face_detector_uint8.pb\"\n","\n","AGE_PROTO = \"/content/Gender-and-Age-Detection/age_deploy.prototxt\"\n","AGE_MODEL = \"/content/Gender-and-Age-Detection/age_net.caffemodel\"\n","\n","GENDER_PROTO = \"/content/Gender-and-Age-Detection/gender_deploy.prototxt\"\n","GENDER_MODEL = \"/content/Gender-and-Age-Detection/gender_net.caffemodel\"\n","\n","# Load network\n","FACE_NET = cv2.dnn.readNet(FACE_MODEL, FACE_PROTO)\n","AGE_NET = cv2.dnn.readNet(AGE_MODEL, AGE_PROTO)\n","GENDER_NET = cv2.dnn.readNet(GENDER_MODEL, GENDER_PROTO)\n","\n","MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n","AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n","GENDER_LIST = [\"Male\", \"Female\"]\n","\n","box_padding = 20\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1675947826805,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"iw8h5l9kaL28"},"outputs":[],"source":["def get_face_box (net, frame, conf_threshold = 0.5):\n","  frame_copy = frame.copy()\n","  frame_height = frame_copy.shape[0]\n","  frame_width = frame_copy.shape[1]\n","  blob = cv2.dnn.blobFromImage(frame_copy, 1.0, (300, 300), [104, 117, 123], True, False)\n","\n","  net.setInput(blob)\n","  detections = net.forward()\n","  boxes = []\n","\n","  for i in range(detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","\n","    if confidence > conf_threshold:\n","      x1 = int(detections[0, 0, i, 3] * frame_width)\n","      y1 = int(detections[0, 0, i, 4] * frame_height)\n","      x2 = int(detections[0, 0, i, 5] * frame_width)\n","      y2 = int(detections[0, 0, i, 6] * frame_height)\n","      boxes.append([x1, y1, x2, y2])\n","      cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), int(round(frame_height / 150)), 8)\n","\n","  return frame_copy, boxes"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1675947829921,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"WKbYxPlraRIr"},"outputs":[],"source":["def age_gender_detector (input_path, filename):\n","  image = cv2.imread(input_path)\n","  resized_image = cv2.resize(image, (640, 480))\n","\n","  frame = resized_image.copy()\n","  frame_face, boxes = get_face_box(FACE_NET, frame)\n","\n","  count = 0\n","  for box in boxes:\n","    frameName.append(filename)\n","    person.append(count)\n","    boxFace.append(box)\n","    face = frame[max(0, box[1] - box_padding):min(box[3] + box_padding, frame.shape[0] - 1), \\\n","      max(0, box[0] - box_padding):min(box[2] + box_padding, frame.shape[1] - 1)]\n","\n","    blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB = False)\n","    GENDER_NET.setInput(blob)\n","    gender_predictions = GENDER_NET.forward()\n","    gender = GENDER_LIST[gender_predictions[0].argmax()]\n","    gen.append(gender)\n","    gender_conf.append(gender_predictions[0].max())\n","\n","    AGE_NET.setInput(blob)\n","    age_predictions = AGE_NET.forward()\n","    age = AGE_LIST[age_predictions[0].argmax()]\n","    ages.append(age)\n","    age_conf.append(age_predictions[0].max())\n","\n","    label = \"{},{}\".format(gender, age)\n","    cv2.putText(frame_face, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n","    cv2.putText(frame_face, str(count), (box[0] + 2, box[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n","\n","    count += 1\n","\n","  if len(boxes) > 0:\n","    cv2.resize(frame_face, (640, 480))\n","    cv2.imwrite(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Agender/Siedler/\" + filename, frame_face)\n","\n","  return frame_face"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1675947834092,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"6rLAric_tZbA"},"outputs":[],"source":["frameName = []\n","person = []\n","boxFace = []\n","gen = []\n","gender_conf = []\n","ages = []\n","age_conf = []"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":21446,"status":"error","timestamp":1675947857520,"user":{"displayName":"Julian Hoepfinger","userId":"12404768957482834205"},"user_tz":-60},"id":"4tgMnttXY12Y","outputId":"51bb6637-fd75-4530-8564-3e38e29e1178"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-66522e5e4f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mage_gender_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d06810d049ab>\u001b[0m in \u001b[0;36mage_gender_detector\u001b[0;34m(input_path, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mage_gender_detector\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["directory = os.fsencode(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\")\n","count = 0\n","for file in os.listdir(directory):\n","  count += 1\n","  if count == 100:\n","    break\n","  \n","  filename = os.fsdecode(file)\n","  age_gender_detector(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\" + filename, filename)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSntHIhZwtSJ"},"outputs":[],"source":["df = pd.DataFrame(list(zip(frameName, person, boxFace, gen, gender_conf, ages, age_conf)))\n","df.columns = ['Name', 'person', 'box', 'gender', 'gender_conf', 'age', 'age_conf']\n","df.to_csv(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Agender/siedler_agender.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNhATMrpwWLZHJPaqkD3pMb","provenance":[]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.9 (main, Dec 15 2022, 18:18:30) [Clang 14.0.0 (clang-1400.0.29.202)]"},"vscode":{"interpreter":{"hash":"b84c6385a660d7f75b973b812e8733d5edf6dc187bff937f407889d8571426b1"}}},"nbformat":4,"nbformat_minor":0}
