{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File for all CV Methods combined so that it runs in a single pipeline\n",
    "\n",
    "1) To install all required packages for this pipeline, use the `installPackages.sh` script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using workaround with rclone\n",
    "#from google.colab.patches import cv2_imshow #can not use on linux\n",
    "#from google.colab import drive #can not use on linux\n",
    "\n",
    "import csv, json, os, math, random, re, sys, statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "\n",
    "from natsort import natsorted, ns\n",
    "from colorthief import ColorThief\n",
    "from fer import FER\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io #scikit-image\n",
    "\n",
    "from torch.autograd import Variable as V\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup logger for detectron2\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGender:\n",
    "  def __init__(self, one):\n",
    "    # Defined the model files\n",
    "    self.FACE_PROTO = \"./models/opencv_face_detector.pbtxt\"\n",
    "    self.FACE_MODEL = \"./models/opencv_face_detector_uint8.pb\"\n",
    "    self.AGE_PROTO = \"./models/age_deploy.prototxt\"\n",
    "    self.AGE_MODEL = \"./models/age_net.caffemodel\"\n",
    "    self.GENDER_PROTO = \"./models/gender_deploy.prototxt\"\n",
    "    self.GENDER_MODEL = \"./models/gender_net.caffemodel\"\n",
    "\n",
    "    # Load network\n",
    "    self.FACE_NET = cv2.dnn.readNet(self.FACE_MODEL, self.FACE_PROTO)\n",
    "    self.AGE_NET = cv2.dnn.readNet(self.AGE_MODEL, self.AGE_PROTO)\n",
    "    self.GENDER_NET = cv2.dnn.readNet(self.GENDER_MODEL, self.GENDER_PROTO)\n",
    "\n",
    "    self.MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "    self.AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "    self.GENDER_LIST = [\"Male\", \"Female\"]\n",
    "\n",
    "    self.box_padding = 20\n",
    "\n",
    "    self.frameName = []\n",
    "    self.person = []\n",
    "    self.boxFace = []\n",
    "    self.gen = []\n",
    "    self.gender_conf = []\n",
    "    self.ages = []\n",
    "    self.age_conf = []\n",
    "\n",
    "  def get_face_box (self, net, frame, conf_threshold = 0.5):\n",
    "    frame_copy = frame.copy()\n",
    "    frame_height = frame_copy.shape[0]\n",
    "    frame_width = frame_copy.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frame_copy, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "      confidence = detections[0, 0, i, 2]\n",
    "\n",
    "      if confidence > conf_threshold:\n",
    "        x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "        y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "        x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "        y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), int(round(frame_height / 150)), 8)\n",
    "\n",
    "    return frame_copy, boxes\n",
    "\n",
    "  def age_gender_detector (self, input_path, filename):\n",
    "    image = cv2.imread(input_path)\n",
    "    resized_image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    frame = resized_image.copy()\n",
    "    frame_face, boxes = self.get_face_box(self.FACE_NET, frame)\n",
    "\n",
    "    count = 0\n",
    "    for box in boxes:\n",
    "      self.frameName.append(filename)\n",
    "      self.person.append(count)\n",
    "      self.boxFace.append(box)\n",
    "      face = frame[max(0, box[1] - self.box_padding):min(box[3] + self.box_padding, frame.shape[0] - 1), \\\n",
    "        max(0, box[0] - self.box_padding):min(box[2] + self.box_padding, frame.shape[1] - 1)]\n",
    "\n",
    "      blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), self.MODEL_MEAN_VALUES, swapRB = False)\n",
    "      self.GENDER_NET.setInput(blob)\n",
    "      gender_predictions = self.GENDER_NET.forward()\n",
    "      gender = self.GENDER_LIST[gender_predictions[0].argmax()]\n",
    "      self.gen.append(gender)\n",
    "      self.gender_conf.append(gender_predictions[0].max())\n",
    "\n",
    "      self.AGE_NET.setInput(blob)\n",
    "      age_predictions = self.AGE_NET.forward()\n",
    "      age = self.AGE_LIST[age_predictions[0].argmax()]\n",
    "      self.ages.append(age)\n",
    "      self.age_conf.append(age_predictions[0].max())\n",
    "\n",
    "      label = \"{},{}\".format(gender, age)\n",
    "      cv2.putText(frame_face, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "      cv2.putText(frame_face, str(count), (box[0] + 2, box[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n",
    "\n",
    "      count += 1\n",
    "\n",
    "#write to file extra\n",
    "    if len(boxes) > 0:\n",
    "      cv2.resize(frame_face, (640, 480))\n",
    "      cv2.imwrite(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Agender/Siedler/\" + filename, frame_face)\n",
    "\n",
    "    return frame_face\n",
    "\n",
    "  def x(self):\n",
    "    # we rerun the pipeline for each game, so assign path with __init__\n",
    "    directory = os.fsencode(\"assetpath with current game\")\n",
    "    count = 0\n",
    "    for file in os.listdir(directory):\n",
    "      count += 1\n",
    "      if count == 100: #use other number here\n",
    "        break\n",
    "      \n",
    "      filename = os.fsdecode(file)\n",
    "      age_gender_detector(\"/content/gdrive/MyDrive/digital_humanities/Walkthroughts/Siedler_Frames/\" + filename, filename)\n",
    "\n",
    "  def saveData(self):\n",
    "    df = pd.DataFrame(list(zip(self.frameName, self.person, self.boxFace, self.gen, self.gender_conf, self.ages, self.age_conf)))\n",
    "    df.columns = ['Name', 'person', 'box', 'gender', 'gender_conf', 'age', 'age_conf']\n",
    "    #change output\n",
    "    df.to_csv(\"/content/gdrive/MyDrive/digital_humanities/Ergebnisse/Agender/siedler_agender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NFSMW', 'Die_Siedler3', 'Elden_Ring', 'Super_Mario_World', 'Starcraft2', 'Diablo2', 'Half_Life2', 'Little_Nightmares']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(dir1)\n\u001b[1;32m      7\u001b[0m \u001b[39m#hopefully there is no DS_Store XD\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(games) \u001b[39m!=\u001b[39m \u001b[39m8\u001b[39m:\n\u001b[1;32m      9\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39massets does not contain \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mwhile\u001b[39;00m games:\n\u001b[1;32m     13\u001b[0m   \u001b[39m#init ageGender\u001b[39;00m\n\u001b[1;32m     14\u001b[0m   \u001b[39m#process ageGender\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[39m#do not load the assets multiple times!\u001b[39;00m\n\u001b[1;32m     25\u001b[0m   \u001b[39m#pass the data with each loop iteration\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "games = 1 #list of the game images in assets/*\n",
    "directory = os.fsencode(\"./assets/\")\n",
    "dir1 = os.listdir(\"./assets/\")\n",
    "\n",
    "print(dir1)\n",
    "\n",
    "#hopefully there is no DS_Store XD\n",
    "if len(games) != 8:\n",
    "  raise Exception(\"assets does not contain \")\n",
    "\n",
    "\n",
    "while games:\n",
    "  #init ageGender\n",
    "  #process ageGender\n",
    "  #save ageGender\n",
    "\n",
    "  #merge color methods in one class\n",
    "\n",
    "  #emotion\n",
    "  #location\n",
    "  #object detection\n",
    "\n",
    "  #tipp:\n",
    "  #do not load the assets multiple times!\n",
    "  #pass the data with each loop iteration\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b84c6385a660d7f75b973b812e8733d5edf6dc187bff937f407889d8571426b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
