{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File for all CV Methods combined so that it runs in a single pipeline\n",
    "\n",
    "1) To install all required packages for this pipeline, use the `installPackages.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, os, math, random, re, sys, statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch, torchvision\n",
    "#import detectron2\n",
    "\n",
    "from natsort import natsorted, ns\n",
    "from colorthief import ColorThief\n",
    "from fer import FER\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io #scikit-image\n",
    "\n",
    "from torch.autograd import Variable as V\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "#from detectron2.utils.logger import setup_logger\n",
    "#from detectron2 import model_zoo\n",
    "#from detectron2.engine import DefaultPredictor\n",
    "#from detectron2.config import get_cfg\n",
    "#from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "#from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#setup logger for detectron2\n",
    "#setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGender:\n",
    "  def __init__(self, outputPathImages, outputPathCSV, name):\n",
    "    self.method = \"AgeGender\"\n",
    "    self.outputPathImages = outputPathImages\n",
    "    self.outputPathImages = self.outputPathImages.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "  \n",
    "    # Defined the model files\n",
    "    self.FACE_PROTO = \"./models/opencv_face_detector.pbtxt\"\n",
    "    self.FACE_MODEL = \"./models/opencv_face_detector_uint8.pb\"\n",
    "    self.AGE_PROTO = \"./models/age_deploy.prototxt\"\n",
    "    self.AGE_MODEL = \"./models/age_net.caffemodel\"\n",
    "    self.GENDER_PROTO = \"./models/gender_deploy.prototxt\"\n",
    "    self.GENDER_MODEL = \"./models/gender_net.caffemodel\"\n",
    "\n",
    "    # Load network\n",
    "    self.FACE_NET = cv2.dnn.readNet(self.FACE_MODEL, self.FACE_PROTO)\n",
    "    self.AGE_NET = cv2.dnn.readNet(self.AGE_MODEL, self.AGE_PROTO)\n",
    "    self.GENDER_NET = cv2.dnn.readNet(self.GENDER_MODEL, self.GENDER_PROTO)\n",
    "\n",
    "    self.MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "    self.AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "    self.GENDER_LIST = [\"Male\", \"Female\"]\n",
    "\n",
    "    self.box_padding = 20\n",
    "\n",
    "    self.frameName = []\n",
    "    self.person = []\n",
    "    self.boxFace = []\n",
    "    self.gen = []\n",
    "    self.gender_conf = []\n",
    "    self.ages = []\n",
    "    self.age_conf = []\n",
    "\n",
    "  def get_face_box (self, net, frame, conf_threshold = 0.5):\n",
    "    frame_copy = frame.copy()\n",
    "    frame_height = frame_copy.shape[0]\n",
    "    frame_width = frame_copy.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frame_copy, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "      confidence = detections[0, 0, i, 2]\n",
    "\n",
    "      if confidence > conf_threshold:\n",
    "        x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "        y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "        x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "        y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), int(round(frame_height / 150)), 8)\n",
    "\n",
    "    return frame_copy, boxes\n",
    "\n",
    "  def handleNextImage(self, fileName, image):\n",
    "    resized_image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    frame = resized_image.copy()\n",
    "    frame_face, boxes = self.get_face_box(self.FACE_NET, frame)\n",
    "\n",
    "    count = 0\n",
    "    for box in boxes:\n",
    "      self.frameName.append(fileName)\n",
    "      self.person.append(count)\n",
    "      self.boxFace.append(box)\n",
    "      face = frame[max(0, box[1] - self.box_padding):min(box[3] + self.box_padding, frame.shape[0] - 1), \\\n",
    "        max(0, box[0] - self.box_padding):min(box[2] + self.box_padding, frame.shape[1] - 1)]\n",
    "\n",
    "      blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), self.MODEL_MEAN_VALUES, swapRB = False)\n",
    "      self.GENDER_NET.setInput(blob)\n",
    "      gender_predictions = self.GENDER_NET.forward()\n",
    "      gender = self.GENDER_LIST[gender_predictions[0].argmax()]\n",
    "      self.gen.append(gender)\n",
    "      self.gender_conf.append(gender_predictions[0].max())\n",
    "\n",
    "      self.AGE_NET.setInput(blob)\n",
    "      age_predictions = self.AGE_NET.forward()\n",
    "      age = self.AGE_LIST[age_predictions[0].argmax()]\n",
    "      self.ages.append(age)\n",
    "      self.age_conf.append(age_predictions[0].max())\n",
    "\n",
    "      label = \"{},{}\".format(gender, age)\n",
    "      cv2.putText(frame_face, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "      cv2.putText(frame_face, str(count), (box[0] + 2, box[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n",
    "\n",
    "      count += 1\n",
    "\n",
    "    #only saves an image if age/gender was found\n",
    "    if len(boxes) > 0:\n",
    "      cv2.resize(frame_face, (640, 480))\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{fileName}\", frame_face)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    if len(self.frameName) > 0:\n",
    "      df = pd.DataFrame(list(zip(self.frameName, self.person, self.boxFace, self.gen, self.gender_conf, self.ages, self.age_conf)))\n",
    "      df.columns = ['Name', 'person', 'box', 'gender', 'gender_conf', 'age', 'age_conf']\n",
    "      df.to_csv(f\"{self.outputPathCSV}{self.name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrightnessAnalyzer:\n",
    "  def __init__(self, outputPathImages, outputPathCSV, name):\n",
    "    self.method = \"Brightness\"\n",
    "    self.outputPathImages = outputPathImages\n",
    "    self.outputPathImages = self.outputPathImages.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.brightness_dict = {}\n",
    "    self.brightness_values_dict = {}\n",
    "    self.statistic_result_dict = {}\n",
    "\n",
    "  def handleNextImage(self, fileName, image):\n",
    "    greyscale_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_brightness = greyscale_img.mean()/255\n",
    "\n",
    "    self.brightness_values_dict[fileName] = img_brightness\n",
    "\n",
    "    self.brightness_dict[fileName] = []\n",
    "    self.brightness_dict[fileName].append(round(img_brightness, 2))\n",
    "    self.brightness_dict[fileName].append(fileName)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    mean_brightness = sum(self.brightness_values_dict.values()) / len(self.brightness_dict)\n",
    "    sd_brightness = statistics.stdev(self.brightness_values_dict.values())\n",
    "    median_brightness = statistics.stdev(self.brightness_values_dict.values())\n",
    "    min_brightness = min(self.brightness_values_dict.values())\n",
    "    max_brightness = max(self.brightness_values_dict.values())\n",
    "\n",
    "    statistic_result_dict = {}\n",
    "    statistic_result_dict[\"min\"] = []\n",
    "    statistic_result_dict[\"min\"].append(round(min_brightness, 2))\n",
    "    statistic_result_dict[\"median\"] = []\n",
    "    statistic_result_dict[\"median\"].append(round(median_brightness, 2))\n",
    "    statistic_result_dict[\"mean\"] = []\n",
    "    statistic_result_dict[\"mean\"].append(round(mean_brightness, 2))\n",
    "    statistic_result_dict[\"sd\"] = []\n",
    "    statistic_result_dict[\"sd\"].append(round(sd_brightness, 2))\n",
    "    statistic_result_dict[\"max\"] = []\n",
    "    statistic_result_dict[\"max\"].append(round(max_brightness, 2))\n",
    "\n",
    "    dataBrightness = pd.DataFrame.from_dict(self.brightness_dict, orient='index', columns=[\"brightness_value\", \"frame\"])\n",
    "    dataResults = pd.DataFrame.from_dict(statistic_result_dict)\n",
    "\n",
    "    cols = dataBrightness.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataBrightness = dataBrightness[cols]\n",
    "\n",
    "    dataBrightness.to_csv(f\"{self.outputPathCSV}{self.name}_Brightness.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "    cols = dataResults.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataResults = dataResults[cols]\n",
    "    \n",
    "    dataResults.to_csv(f\"{self.outputPathCSV}{self.name}_Statistics.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomColorThief(ColorThief):\n",
    "  def __init__(self, image):\n",
    "    self.image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "class DominantColor:\n",
    "  def __init__(self, outputPathCSV, name):\n",
    "    self.method = \"DominantColor\"\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.dominant_color_arr = []\n",
    "\n",
    "  def handleNextImage(self, image):\n",
    "    ct_frame = CustomColorThief(image)\n",
    "    # change quality to \"2\" to get the second most dominat color\n",
    "    dominant_color_of_ct_frame = ct_frame.get_color(quality=1)\n",
    "    self.dominant_color_arr.append(dominant_color_of_ct_frame)\n",
    "\n",
    "  def generateColorBars(self):\n",
    "    plt.imshow([[self.dominant_color_arr[i] for i in range(len(self.dominant_color_arr))]], extent=[0,len(self.dominant_color_arr),0,1], aspect='auto')\n",
    "\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_dominant_color_for_each_frame.eps\", format='eps')\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_dominant_color_for_each_frame.svg\", format='svg')\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_dominant_color_for_each_frame.png\")\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_dominant_color_for_each_frame.jpg\")\n",
    "  \n",
    "  def dataToCSV(self):\n",
    "    dominant_color_row_data = pd.DataFrame.from_dict(self.dominant_color_dict, orient='index', columns=[\"RGB\", \"frame\"])\n",
    "    \n",
    "    cols_row_data = dominant_color_row_data.columns.tolist()\n",
    "    cols_row_data = cols_row_data[-1:] + cols_row_data[:-1]\n",
    "    dominant_color_row_data = dominant_color_row_data[cols_row_data]\n",
    "    \n",
    "    dominant_color_row_data.to_csv(f\"{self.outputPathCSV}{self.name}_dominant_color_row_data.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageColor:\n",
    "  def __init__(self, outputPathCSV, name):\n",
    "    self.method = \"AverageColor\"\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.averageColorArr = []\n",
    "\n",
    "  def handleNextImage(self, image):\n",
    "    average_color_row = np.average(image, axis=0)\n",
    "    average_color = np.average(average_color_row, axis=0)\n",
    "\n",
    "    average_color_tuple = tuple(average_color)\n",
    "\n",
    "    self.averageColorArr.append(average_color_tuple)\n",
    "\n",
    "  def generateColorBars(self):\n",
    "    self.averageColorArr = tuple(tuple(map(int, tup)) for tup in self.averageColorArr)\n",
    "    \n",
    "    plt.imshow([[self.averageColorArr[i] for i in range(len(self.averageColorArr))]], extent=[0,len(self.averageColorArr),0,1], aspect='auto')\n",
    "\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_average_color_for_each_frame.eps\", format='eps')\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_average_color_for_each_frame.svg\", format='svg')\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_average_color_for_each_frame.png\")\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.name}_average_color_for_each_frame.jpg\")\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    average_color_row_data = pd.DataFrame.from_dict(self.average_color_dict, orient='index', columns=[\"RGB\", \"frame\"])\n",
    "    \n",
    "    cols_row_data = average_color_row_data.columns.tolist()\n",
    "    cols_row_data = cols_row_data[-1:] + cols_row_data[:-1]\n",
    "    average_color_row_data = average_color_row_data[cols_row_data]\n",
    "    \n",
    "    average_color_row_data.to_csv(f\"{self.outputPathCSV}{self.name}_average_color_row_data.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDetection:\n",
    "  def __init__(self, outputPathImages, outputPathCSV, name):\n",
    "    self.method = \"EmotionDetection\"\n",
    "    self.outputPathImages = outputPathImages\n",
    "    self.outputPathImages = self.outputPathImages.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.detectorMT = FER(mtcnn=True)\n",
    "\n",
    "    self.emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    self.categories = ['box', 'emotions']\n",
    "\n",
    "    self.frame = []\n",
    "    self.person = []\n",
    "    self.box = []\n",
    "    self.angry = []\n",
    "    self.disgust = []\n",
    "    self.fear = []\n",
    "    self.happy = []\n",
    "    self.sad = []\n",
    "    self.suprise = []\n",
    "    self.neutral = []\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    prediction = self.detectorMT.detect_emotions(frameData)\n",
    "\n",
    "    for n in range(len(prediction)):\n",
    "      bbox = prediction[n][self.categories[0]]\n",
    "      img = cv2.rectangle(frameData, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]),(0, 255, 0), 1,)\n",
    "      cv2.putText(img, str(n), (bbox[0] + 2, bbox[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n",
    "      self.frame.append(frameName)\n",
    "      self.person.append(n)\n",
    "      self.box.append(bbox)\n",
    "      self.angry.append(prediction[n][self.categories[1]][self.emotions[0]])\n",
    "      self.disgust.append(prediction[n][self.categories[1]][self.emotions[1]])\n",
    "      self.fear.append(prediction[n][self.categories[1]][self.emotions[2]])\n",
    "      self.happy.append(prediction[n][self.categories[1]][self.emotions[3]])\n",
    "      self.sad.append(prediction[n][self.categories[1]][self.emotions[4]])\n",
    "      self.suprise.append(prediction[n][self.categories[1]][self.emotions[5]])\n",
    "      self.neutral.append(prediction[n][self.categories[1]][self.emotions[6]])\n",
    "\n",
    "    if len(prediction) > 0:\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{frameName}\", img)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    df = pd.DataFrame(list(zip(self.frame, self.person, self.box, self.angry, self.disgust, self.fear, self.happy, self.sad, self.suprise, self.neutral)))\n",
    "    df.columns = ['Name', 'person', 'box', 'angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    df.to_csv(f\"{self.outputPathCSV}{self.name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationDetection:\n",
    "  def __init__(self, outputPathImages, outputPathCSV, name):\n",
    "    self.method = \"LocationDetection\"\n",
    "    self.outputPathImages = outputPathImages\n",
    "    self.outputPathImages = self.outputPathImages.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.CATEGORIES_PLACES = \"./models/categories_places365.txt\"\n",
    "    self.IO_PLACES = \"./models/IO_places365.txt\"\n",
    "    self.LABELS_SUNATTRIBUTE = \"./models/labels_sunattribute.txt\"\n",
    "    self.SCENE_ATTRIBUTE_NPY = \"./models/W_sceneattribute_wideresnet18.npy\"\n",
    "\n",
    "    self.classes = None\n",
    "    self.labels_IO = None\n",
    "    self.labels_attribute = None\n",
    "    self.W_attribute = None\n",
    "\n",
    "    self.features_blobs = []\n",
    "    self.load_labels()\n",
    "    self.model = self.load_model()\n",
    "    self.tf = self.returnTF()\n",
    "\n",
    "    self.params = list(self.model.parameters())\n",
    "    self.weight_softmax = self.params[-2].data.numpy()\n",
    "    self.weight_softmax[self.weight_softmax<0] = 0\n",
    "\n",
    "    self.frame_names = []\n",
    "    self.io_score = []\n",
    "    self.io = []\n",
    "    self.prob_cat_1 = []\n",
    "    self.cat_1 = []\n",
    "    self.prob_cat_2 = []\n",
    "    self.cat_2 = []\n",
    "    self.prob_cat_3 = []\n",
    "    self.cat_3 = []\n",
    "    self.prob_cat_4 = []\n",
    "    self.cat_4 = []\n",
    "    self.prob_cat_5 = []\n",
    "    self.cat_5 = []\n",
    "\n",
    "  def load_labels(self):\n",
    "    c = list()\n",
    "    with open(self.CATEGORIES_PLACES) as class_file:\n",
    "      for line in class_file:\n",
    "        c.append(line.strip().split(' ')[0][3:])\n",
    "    self.classes = tuple(c)\n",
    "\n",
    "    with open(self.IO_PLACES) as f:\n",
    "      lines = f.readlines()\n",
    "      labels_IO = []\n",
    "      for line in lines:\n",
    "        items = line.rstrip().split()\n",
    "        labels_IO.append(int(items[-1]) -1) # 0 is indoor, 1 is outdoor\n",
    "    self.labels_IO = np.array(labels_IO)\n",
    "\n",
    "    with open(self.LABELS_SUNATTRIBUTE) as f:\n",
    "      lines = f.readlines()\n",
    "      self.labels_attribute = [item.rstrip() for item in lines]\n",
    "\n",
    "    self.W_attribute = np.load(self.SCENE_ATTRIBUTE_NPY)\n",
    "\n",
    "  def load_model(self):#TODO\n",
    "    # this model has a last conv feature map as 14x14\n",
    "    import models.wideresnet as wideresnet\n",
    "    model = wideresnet.resnet18(num_classes=365)\n",
    "    checkpoint = torch.load(\"./models/wideresnet18_places365.pth.tar\", map_location=lambda storage, loc: storage)\n",
    "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # hacky way to deal with the upgraded batchnorm2D and avgpool layers...\n",
    "    for i, (name, module) in enumerate(model._modules.items()):\n",
    "        module = self.recursion_change_bn(model)\n",
    "    model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # the following is deprecated, everything is migrated to python36\n",
    "\n",
    "    ## if you encounter the UnicodeDecodeError when use python3 to load the model, add the following line will fix it. Thanks to @soravux\n",
    "    #from functools import partial\n",
    "    #import pickle\n",
    "    #pickle.load = partial(pickle.load, encoding=\"latin1\")\n",
    "    #pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")\n",
    "    #model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle)\n",
    "\n",
    "    model.eval()\n",
    "    # hook the feature extractor\n",
    "    features_names = ['layer4','avgpool'] # this is the last conv layer of the resnet\n",
    "    for name in features_names:\n",
    "        model._modules.get(name).register_forward_hook(self.hook_feature)\n",
    "    return model\n",
    "\n",
    "  # hacky way to deal with the Pytorch 1.0 update\n",
    "  def recursion_change_bn(self, module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "      module.track_running_stats = 1\n",
    "    else:\n",
    "      for i, (name, module1) in enumerate(module._modules.items()):\n",
    "        module1 = self.recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "  def hook_feature(self, module, input, output):\n",
    "    self.features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
    "\n",
    "  def returnCAM(self, feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "  def returnTF(self):\n",
    "  # load the image transformer\n",
    "    tf = trn.Compose([\n",
    "      trn.Resize((224,224)),\n",
    "      trn.ToTensor(),\n",
    "      trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return tf\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    imageCopy = frameData.copy()\n",
    "    image = Image.fromarray(cv2.cvtColor(frameData, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    input_img = V(self.tf(image).unsqueeze(0))   \n",
    "    logit = self.model.forward(input_img)\n",
    "    h_x = F.softmax(logit, 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy() \n",
    "\n",
    "    io_image = np.mean(self.labels_IO[idx[:10]])\n",
    "    self.io_score.append(io_image)\n",
    "    if io_image < 0.5:\n",
    "      self.io.append(\"indoor\")\n",
    "    else:\n",
    "      self.io.append(\"outdoor\")\n",
    "    \n",
    "    self.prob_cat_1.append(probs[0])\n",
    "    self.cat_1.append(self.classes[idx[0]])\n",
    "    self.prob_cat_2.append(probs[1])\n",
    "    self.cat_2.append(self.classes[idx[1]])\n",
    "    self.prob_cat_3.append(probs[2])\n",
    "    self.cat_3.append(self.classes[idx[2]])\n",
    "    self.prob_cat_4.append(probs[3])\n",
    "    self.cat_4.append(self.classes[idx[3]])\n",
    "    self.prob_cat_5.append(probs[4])\n",
    "    self.cat_5.append(self.classes[idx[4]])\n",
    "\n",
    "    loc1 = \"Location 1: {} ({})\". format(self.cat_1[len(self.cat_1)-1], \"{:.2f}\".format(self.prob_cat_1[len(self.prob_cat_1)-1]))\n",
    "    loc2 = \"Location 2: {} ({})\". format(self.cat_2[len(self.cat_2)-1], \"{:.2f}\".format(self.prob_cat_2[len(self.prob_cat_2)-1]))\n",
    "    loc3 = \"Location 3: {} ({})\". format(self.cat_3[len(self.cat_3)-1], \"{:.2f}\".format(self.prob_cat_3[len(self.prob_cat_3)-1]))\n",
    "    cat = \"Category: {}\".format(self.io[len(self.io)-1])\n",
    "\n",
    "    color = (255,255,255)\n",
    "    cv2.putText(imageCopy, loc1, (20, 40), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, loc2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, loc3, (20, 80), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, cat, (20, 110), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    \n",
    "    cv2.imwrite(f\"{self.outputPathImages}{frameName}\", imageCopy)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    df = pd.DataFrame(list(zip(self.frame_names, self.io_score, self.io, self.prob_cat_1, self.cat_1, self.prob_cat_2, self.cat_2, self.prob_cat_3, self.cat_3, self.prob_cat_4, self.cat_4, self.prob_cat_5, self.cat_5)))\n",
    "    df.columns = ['Name', 'io_score', 'io', 'prob_cat_1', 'cat_1', 'prob_cat_2', 'cat_2', 'prob_cat_3', 'cat_3', 'prob_cat_4', 'cat_4', 'prob_cat_5', 'cat_5']\n",
    "    df.to_csv(f\"{self.outputPathCSV}{self.name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "  def __init__(self, outputPathImages, outputPathCSV, name):\n",
    "    self.method = \"EmotionDetection\"\n",
    "    self.outputPathImages = outputPathImages\n",
    "    self.outputPathImages = self.outputPathImages.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.outputPathCSV = outputPathCSV\n",
    "    self.outputPathCSV = self.outputPathCSV.replace(\"{cv_method}\", f\"{self.method}\")\n",
    "    self.name = name\n",
    "\n",
    "    self.threshold = 0.5\n",
    "    self.createImages = True\n",
    "    self.predictor = None\n",
    "    self.cfg = None\n",
    "    self.classDict = None\n",
    "    self.allDic = []\n",
    "    \n",
    "    self.checkGPU()\n",
    "    self.loadClasses()\n",
    "   \n",
    "  def checkGPU():\n",
    "    # If there's a GPU available...\n",
    "    if torch.cuda.is_available():    \n",
    "        # Tell PyTorch to use the GPU.    \n",
    "        device = torch.device(\"cuda\")\n",
    "\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "    # If not...\n",
    "    else:\n",
    "        #device = torch.device(\"cpu\")\n",
    "        raise Exception(\"No GPU available, using the CPU instead.\")\n",
    "\n",
    "  #all underlined methods and classes are imports from detectron\n",
    "  def configDetectron(self):\n",
    "    self.cfg = get_cfg()\n",
    "\n",
    "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "    self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.threshold  # set threshold for this model\n",
    "\n",
    "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "    self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "    self.predictor = DefaultPredictor(cfg)\n",
    "\n",
    "  def loadClasses(self):\n",
    "    self.classDict = {0: u'__background__',\n",
    "      1: u'person',\n",
    "      2: u'bicycle',\n",
    "      3: u'car',\n",
    "      4: u'motorcycle',\n",
    "      5: u'airplane',\n",
    "      6: u'bus',\n",
    "      7: u'train',\n",
    "      8: u'truck',\n",
    "      9: u'boat',\n",
    "      10: u'traffic light',\n",
    "      11: u'fire hydrant',\n",
    "      12: u'stop sign',\n",
    "      13: u'parking meter',\n",
    "      14: u'bench',\n",
    "      15: u'bird',\n",
    "      16: u'cat',\n",
    "      17: u'dog',\n",
    "      18: u'horse',\n",
    "      19: u'sheep',\n",
    "      20: u'cow',\n",
    "      21: u'elephant',\n",
    "      22: u'bear',\n",
    "      23: u'zebra',\n",
    "      24: u'giraffe',\n",
    "      25: u'backpack',\n",
    "      26: u'umbrella',\n",
    "      27: u'handbag',\n",
    "      28: u'tie',\n",
    "      29: u'suitcase',\n",
    "      30: u'frisbee',\n",
    "      31: u'skis',\n",
    "      32: u'snowboard',\n",
    "      33: u'sports ball',\n",
    "      34: u'kite',\n",
    "      35: u'baseball bat',\n",
    "      36: u'baseball glove',\n",
    "      37: u'skateboard',\n",
    "      38: u'surfboard',\n",
    "      39: u'tennis racket',\n",
    "      40: u'bottle',\n",
    "      41: u'wine glass',\n",
    "      42: u'cup',\n",
    "      43: u'fork',\n",
    "      44: u'knife',\n",
    "      45: u'spoon',\n",
    "      46: u'bowl',\n",
    "      47: u'banana',\n",
    "      48: u'apple',\n",
    "      49: u'sandwich',\n",
    "      50: u'orange',\n",
    "      51: u'broccoli',\n",
    "      52: u'carrot',\n",
    "      53: u'hot dog',\n",
    "      54: u'pizza',\n",
    "      55: u'donut',\n",
    "      56: u'cake',\n",
    "      57: u'chair',\n",
    "      58: u'couch',\n",
    "      59: u'potted plant',\n",
    "      60: u'bed',\n",
    "      61: u'dining table',\n",
    "      62: u'toilet',\n",
    "      63: u'tv',\n",
    "      64: u'laptop',\n",
    "      65: u'mouse',\n",
    "      66: u'remote',\n",
    "      67: u'keyboard',\n",
    "      68: u'cell phone',\n",
    "      69: u'microwave',\n",
    "      70: u'oven',\n",
    "      71: u'toaster',\n",
    "      72: u'sink',\n",
    "      73: u'refrigerator',\n",
    "      74: u'book',\n",
    "      75: u'clock',\n",
    "      76: u'vase',\n",
    "      77: u'scissors',\n",
    "      78: u'teddy bear',\n",
    "      79: u'hair drier',\n",
    "      80: u'toothbrush'}\n",
    "\n",
    "  def createBaseDict(self):\n",
    "    baseDict = {v: k for k,v in self.classDict.items()}\n",
    "    del baseDict[\"__background__\"]\n",
    "    for item in baseDict:\n",
    "      baseDict[item] = 0\n",
    "    return baseDict\n",
    "\n",
    "  def getObjectsPerFrame(self, classes):\n",
    "    frameDict = self.createBaseDict()\n",
    "    for item in classes:\n",
    "      classNumber = item.item() + 1\n",
    "      className = self.classDict[classNumber]\n",
    "\n",
    "      frameDict[className] = frameDict[className] + 1\n",
    "\n",
    "    return frameDict\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    outputs = self.predictor(frameData)\n",
    "    instances = outputs[\"instances\"].pred_classes\n",
    "    frame = self.getObjectsPerFrame(instances)\n",
    "    frame[\"_id\"] = frameName.split(\".\")[0]\n",
    "\n",
    "    self.allDic.append(frameName)\n",
    "\n",
    "    if self.createImages:\n",
    "      v = Visualizer(frameData[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.0)\n",
    "      out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{frameName}\", out.get_image()[:, :, ::-1])\n",
    "   \n",
    "\n",
    "  def dataToCSV(self):\n",
    "    data = pd.DataFrame.from_dict(self.allDic)\n",
    "    data = data.reindex(sorted(data.columns), axis=1)\n",
    "\n",
    "    #data = data.sort_values(\"_id\")\n",
    "    data[\"sum\"] = data.loc[:, \"airplane\":\"zebra\"].sum(1)\n",
    "    data.to_csv(f\"{self.outputPathCSV}{self.name}.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siedler_frame_0.jpg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg']}\n",
      "siedler_frame_30.jpg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg'], 'siedler_frame_30.jpg': [0.27, 'siedler_frame_30.jpg']}\n",
      "siedler_frame_60.jpg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg'], 'siedler_frame_30.jpg': [0.27, 'siedler_frame_30.jpg'], 'siedler_frame_60.jpg': [0.25, 'siedler_frame_60.jpg']}\n",
      "siedler_frame_90.jpg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg'], 'siedler_frame_30.jpg': [0.27, 'siedler_frame_30.jpg'], 'siedler_frame_60.jpg': [0.25, 'siedler_frame_60.jpg'], 'siedler_frame_90.jpg': [0.08, 'siedler_frame_90.jpg']}\n",
      "siedler_frame_120.jpg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg'], 'siedler_frame_30.jpg': [0.27, 'siedler_frame_30.jpg'], 'siedler_frame_60.jpg': [0.25, 'siedler_frame_60.jpg'], 'siedler_frame_90.jpg': [0.08, 'siedler_frame_90.jpg'], 'siedler_frame_120.jpg': [0.07, 'siedler_frame_120.jpg']}\n",
      "Trump.jpeg {'siedler_frame_0.jpg': [0.54, 'siedler_frame_0.jpg'], 'siedler_frame_30.jpg': [0.27, 'siedler_frame_30.jpg'], 'siedler_frame_60.jpg': [0.25, 'siedler_frame_60.jpg'], 'siedler_frame_90.jpg': [0.08, 'siedler_frame_90.jpg'], 'siedler_frame_120.jpg': [0.07, 'siedler_frame_120.jpg'], 'Trump.jpeg': [0.37, 'Trump.jpeg']}\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'output\\Brightness'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m#save data as csv\u001b[39;00m\n\u001b[0;32m     39\u001b[0m ageGender\u001b[39m.\u001b[39mdataToCSV()\n\u001b[1;32m---> 40\u001b[0m brightnessAnalyzer\u001b[39m.\u001b[39;49mdataToCSV()\n\u001b[0;32m     41\u001b[0m dominantColor\u001b[39m.\u001b[39mdataToCSV()\n\u001b[0;32m     42\u001b[0m averageColor\u001b[39m.\u001b[39mdataToCSV()\n",
      "Cell \u001b[1;32mIn[17], line 51\u001b[0m, in \u001b[0;36mBrightnessAnalyzer.dataToCSV\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m cols \u001b[39m=\u001b[39m cols[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:] \u001b[39m+\u001b[39m cols[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     49\u001b[0m dataBrightness \u001b[39m=\u001b[39m dataBrightness[cols]\n\u001b[1;32m---> 51\u001b[0m dataBrightness\u001b[39m.\u001b[39;49mto_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputPathCSV\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m_Brightness.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     53\u001b[0m cols \u001b[39m=\u001b[39m dataResults\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     54\u001b[0m cols \u001b[39m=\u001b[39m cols[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:] \u001b[39m+\u001b[39m cols[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'output\\Brightness'"
     ]
    }
   ],
   "source": [
    "assetsList = os.listdir(\"./assets/\")\n",
    "\n",
    "#check the content size of all assets for processingTime\n",
    "\n",
    "#build folder structure for input/ouput\n",
    "#put images in folders\n",
    "\n",
    "#print(f'\\rProcessing: {str(len(brightness_values_dict))} of {str(len(frames_list))} Frames have been analyzed.', end='')\n",
    "\n",
    "configList = open(\"./config.json\", \"rb\")\n",
    "gamesList = json.load(configList)\n",
    "\n",
    "for game in gamesList:\n",
    "  ageGender = AgeGender(game[\"outputPathImage\"], game[\"outputPathCSV\"], game[\"name\"])\n",
    "  brightnessAnalyzer = BrightnessAnalyzer(game[\"outputPathImage\"], game[\"outputPathCSV\"], game[\"name\"])\n",
    "  dominantColor = DominantColor(game[\"outputPathCSV\"], game[\"name\"])\n",
    "  averageColor = AverageColor(game[\"outputPathCSV\"], game[\"name\"])\n",
    "  emotionDetection = EmotionDetection(game[\"outputPathImage\"], game[\"outputPathCSV\"], game[\"name\"])\n",
    "  locationDetection = LocationDetection(game[\"outputPathImage\"], game[\"outputPathCSV\"], game[\"name\"])\n",
    "\n",
    "  framesList = os.listdir(game[\"inputPath\"])\n",
    "  framesList = natsorted(framesList, alg=ns.PATH | ns.IGNORECASE)\n",
    "\n",
    "  #report length\n",
    "  for frameName in framesList:\n",
    "    if not frameName.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n",
    "      continue\n",
    "    \n",
    "    frameData = cv2.imread(f\"{game['inputPath']}{frameName}\")\n",
    "    \n",
    "    ageGender.handleNextImage(frameName, frameData)\n",
    "    brightnessAnalyzer.handleNextImage(frameName, frameData)\n",
    "    dominantColor.handleNextImage(frameData)\n",
    "    averageColor.handleNextImage(frameData)\n",
    "    emotionDetection.handleNextImage(frameName, frameData)\n",
    "    locationDetection.handleNextImage(frameName, frameData)\n",
    "  \n",
    "  #save data as csv\n",
    "  ageGender.dataToCSV()\n",
    "  brightnessAnalyzer.dataToCSV()\n",
    "  dominantColor.dataToCSV()\n",
    "  averageColor.dataToCSV()\n",
    "  emotionDetection.dataToCSV()\n",
    "  locationDetection.dataToCSV()\n",
    "\n",
    "  #generate color bars\n",
    "  dominantColor.generateColorBars()\n",
    "  averageColor.generateColorBars()\n",
    "\n",
    "#\n",
    "#processing time report with each picture\n",
    "#\n",
    "#report if all files have been generated /checksum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6540d84677c43a09ba77dca21a04ef847cd39b5846de4b170515afa4945c7b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
