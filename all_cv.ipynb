{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File for all CV Methods combined so that it runs in a single pipeline\n",
    "\n",
    "1) To install all required packages for this pipeline, use the `installPackages.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==1.4.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (4.9.3)\n",
      "Requirement already satisfied: anyio==3.6.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 3)) (3.6.2)\n",
      "Requirement already satisfied: argon2-cffi==21.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.2.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (1.2.3)\n",
      "Requirement already satisfied: asttokens==2.2.1 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: attrs==22.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 9)) (22.2.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.11.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 11)) (4.11.2)\n",
      "Requirement already satisfied: black==23.1.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 12)) (23.1.0)\n",
      "Requirement already satisfied: bleach==6.0.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 13)) (6.0.0)\n",
      "Requirement already satisfied: cachetools==5.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 14)) (5.3.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 15)) (2022.12.7)\n",
      "Requirement already satisfied: cffi==1.15.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 16)) (1.15.1)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 17)) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer==3.0.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 18)) (3.0.1)\n",
      "Requirement already satisfied: click==8.1.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 19)) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 20)) (2.2.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 21)) (0.4.6)\n",
      "Requirement already satisfied: colorthief==0.2.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 22)) (0.2.1)\n",
      "Requirement already satisfied: comm==0.1.2 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 23)) (0.1.2)\n",
      "Requirement already satisfied: contourpy==1.0.7 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 24)) (1.0.7)\n",
      "Requirement already satisfied: cycler==0.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 25)) (0.11.0)\n",
      "Requirement already satisfied: debugpy==1.6.6 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 26)) (1.6.6)\n",
      "Requirement already satisfied: decorator==4.4.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 27)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 28)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 29)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 30)) (1.2.0)\n",
      "Requirement already satisfied: facenet-pytorch==2.5.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 31)) (2.5.2)\n",
      "Requirement already satisfied: fastjsonschema==2.16.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 32)) (2.16.2)\n",
      "Requirement already satisfied: fer==22.5.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 33)) (22.5.0)\n",
      "Requirement already satisfied: flatbuffers==23.1.21 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 34)) (23.1.21)\n",
      "Requirement already satisfied: fonttools==4.38.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 35)) (4.38.0)\n",
      "Requirement already satisfied: fqdn==1.5.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 36)) (1.5.1)\n",
      "Requirement already satisfied: fvcore==0.1.5.post20221221 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 37)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 38)) (0.4.0)\n",
      "Requirement already satisfied: google-auth==1.4.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 39)) (1.4.2)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.6 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 40)) (0.4.6)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 41)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.51.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 42)) (1.51.1)\n",
      "Requirement already satisfied: h5py==3.8.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 43)) (3.8.0)\n",
      "Requirement already satisfied: hydra-core==1.3.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 44)) (1.3.1)\n",
      "Requirement already satisfied: idna==2.8 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 45)) (2.8)\n",
      "Requirement already satisfied: imageio==2.25.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 46)) (2.25.0)\n",
      "Requirement already satisfied: imageio-ffmpeg==0.4.8 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 47)) (0.4.8)\n",
      "Requirement already satisfied: iopath==0.1.9 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 48)) (0.1.9)\n",
      "Requirement already satisfied: ipykernel==6.21.1 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 49)) (6.21.1)\n",
      "Requirement already satisfied: ipython==8.10.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 50)) (8.10.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 51)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==8.0.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 52)) (8.0.4)\n",
      "Requirement already satisfied: isoduration==20.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 53)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.18.2 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 54)) (0.18.2)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 55)) (3.1.2)\n",
      "Requirement already satisfied: jsonpointer==2.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 56)) (2.3)\n",
      "Requirement already satisfied: jsonschema==4.17.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 57)) (4.17.3)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 58)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-console==6.5.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 59)) (6.5.0)\n",
      "Requirement already satisfied: jupyter-events==0.6.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 60)) (0.6.3)\n",
      "Requirement already satisfied: jupyter_client==8.0.2 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 61)) (8.0.2)\n",
      "Requirement already satisfied: jupyter_core==5.2.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 62)) (5.2.0)\n",
      "Requirement already satisfied: jupyter_server==2.2.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 63)) (2.2.1)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.4.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 64)) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.2.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 65)) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.5 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 66)) (3.0.5)\n",
      "Requirement already satisfied: keras==2.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 67)) (2.11.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 68)) (1.4.4)\n",
      "Requirement already satisfied: libclang==15.0.6.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 69)) (15.0.6.1)\n",
      "Requirement already satisfied: Markdown==3.4.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 70)) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe==2.1.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 71)) (2.1.2)\n",
      "Requirement already satisfied: matplotlib==3.6.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 72)) (3.6.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 73)) (0.1.6)\n",
      "Requirement already satisfied: mistune==2.0.5 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 74)) (2.0.5)\n",
      "Requirement already satisfied: moviepy==1.0.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 75)) (1.0.3)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 76)) (1.0.0)\n",
      "Requirement already satisfied: natsort==8.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 77)) (8.2.0)\n",
      "Requirement already satisfied: nbclassic==0.5.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 78)) (0.5.1)\n",
      "Requirement already satisfied: nbclient==0.7.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 79)) (0.7.2)\n",
      "Requirement already satisfied: nbconvert==7.2.9 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 80)) (7.2.9)\n",
      "Requirement already satisfied: nbformat==5.7.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 81)) (5.7.3)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 82)) (1.5.6)\n",
      "Requirement already satisfied: networkx==3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 83)) (3.0)\n",
      "Requirement already satisfied: notebook==6.5.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 84)) (6.5.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 85)) (0.2.2)\n",
      "Requirement already satisfied: numpy==1.24.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 86)) (1.24.2)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 87)) (3.2.2)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 88)) (2.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python==4.7.0.68 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 89)) (4.7.0.68)\n",
      "Requirement already satisfied: opencv-python==4.7.0.68 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 90)) (4.7.0.68)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 91)) (3.3.0)\n",
      "Requirement already satisfied: packaging==23.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 92)) (23.0)\n",
      "Requirement already satisfied: pandas==1.5.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 93)) (1.5.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 94)) (1.5.0)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 95)) (0.8.3)\n",
      "Requirement already satisfied: pathspec==0.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 96)) (0.11.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 97)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.4.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 98)) (9.4.0)\n",
      "Requirement already satisfied: platformdirs==3.0.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 99)) (3.0.0)\n",
      "Requirement already satisfied: portalocker==2.7.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 100)) (2.7.0)\n",
      "Requirement already satisfied: portpicker==1.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 101)) (1.2.0)\n",
      "Requirement already satisfied: proglog==0.1.10 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 102)) (0.1.10)\n",
      "Requirement already satisfied: prometheus-client==0.16.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 103)) (0.16.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.36 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 104)) (3.0.36)\n",
      "Requirement already satisfied: protobuf==3.19.6 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 105)) (3.19.6)\n",
      "Requirement already satisfied: psutil==5.9.4 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 106)) (5.9.4)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 107)) (0.2.2)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 108)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 109)) (0.2.8)\n",
      "Requirement already satisfied: pycocotools==2.0.6 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 110)) (2.0.6)\n",
      "Requirement already satisfied: pycparser==2.21 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 111)) (2.21)\n",
      "Requirement already satisfied: Pygments==2.14.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 112)) (2.14.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 113)) (3.0.9)\n",
      "Requirement already satisfied: pyrsistent==0.19.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 114)) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 115)) (2.8.2)\n",
      "Requirement already satisfied: python-json-logger==2.0.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 116)) (2.0.4)\n",
      "Requirement already satisfied: pytz==2022.7.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 117)) (2022.7.1)\n",
      "Requirement already satisfied: PyWavelets==1.4.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 118)) (1.4.1)\n",
      "Requirement already satisfied: pywin32==305 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 119)) (305)\n",
      "Requirement already satisfied: pywinpty==2.0.10 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 120)) (2.0.10)\n",
      "Requirement already satisfied: PyYAML==6.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 121)) (6.0)\n",
      "Requirement already satisfied: pyzmq==25.0.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 122)) (25.0.0)\n",
      "Requirement already satisfied: qtconsole==5.4.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 123)) (5.4.0)\n",
      "Requirement already satisfied: QtPy==2.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 124)) (2.3.0)\n",
      "Requirement already satisfied: requests==2.21.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 125)) (2.21.0)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 126)) (1.3.1)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 127)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 128)) (0.1.1)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 129)) (4.9)\n",
      "Requirement already satisfied: scikit-image==0.19.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 130)) (0.19.3)\n",
      "Requirement already satisfied: scipy==1.10.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 131)) (1.10.0)\n",
      "Requirement already satisfied: Send2Trash==1.8.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 132)) (1.8.0)\n",
      "Requirement already satisfied: simplegeneric==0.8.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 133)) (0.8.1)\n",
      "Requirement already satisfied: six==1.12.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 134)) (1.12.0)\n",
      "Requirement already satisfied: sniffio==1.3.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 135)) (1.3.0)\n",
      "Requirement already satisfied: soupsieve==2.3.2.post1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 136)) (2.3.2.post1)\n",
      "Requirement already satisfied: stack-data==0.6.2 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 137)) (0.6.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 138)) (0.9.0)\n",
      "Requirement already satisfied: tensorboard==2.11.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 139)) (2.11.2)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 140)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 141)) (1.8.1)\n",
      "Requirement already satisfied: tensorflow==2.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 142)) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 143)) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 144)) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 145)) (0.30.0)\n",
      "Requirement already satisfied: termcolor==2.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 146)) (2.2.0)\n",
      "Requirement already satisfied: terminado==0.17.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 147)) (0.17.1)\n",
      "Requirement already satisfied: tifffile==2023.2.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 148)) (2023.2.3)\n",
      "Requirement already satisfied: tinycss2==1.2.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 149)) (1.2.1)\n",
      "Requirement already satisfied: tomli==2.0.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 150)) (2.0.1)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 151)) (1.13.1)\n",
      "Requirement already satisfied: torchvision==0.14.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 152)) (0.14.1)\n",
      "Requirement already satisfied: tornado==6.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 153)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 154)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.9.0 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 155)) (5.9.0)\n",
      "Requirement already satisfied: typing_extensions==4.4.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 156)) (4.4.0)\n",
      "Requirement already satisfied: uri-template==1.2.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 157)) (1.2.0)\n",
      "Requirement already satisfied: urllib3==1.24.3 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 158)) (1.24.3)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 159)) (0.2.6)\n",
      "Requirement already satisfied: webcolors==1.12 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 160)) (1.12)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 161)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.5.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 162)) (1.5.1)\n",
      "Requirement already satisfied: Werkzeug==2.2.2 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 163)) (2.2.2)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.5 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 164)) (4.0.5)\n",
      "Requirement already satisfied: wrapt==1.14.1 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 165)) (1.14.1)\n",
      "Requirement already satisfied: yacs==0.1.8 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 166)) (0.1.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\micha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse==1.6.3->-r requirements.txt (line 8)) (0.38.4)\n",
      "INFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tabulate==0.9.0\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of stack-data to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting stack-data==0.6.2\n",
      "  Using cached stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of soupsieve to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting soupsieve==2.3.2.post1\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "INFO: pip is looking at multiple versions of sniffio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sniffio==1.3.0\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "INFO: pip is looking at multiple versions of six to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting six==1.12.0\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "INFO: pip is looking at multiple versions of simplegeneric to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting simplegeneric==0.8.1\n",
      "  Using cached simplegeneric-0.8.1-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of send2trash to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Send2Trash==1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy==1.10.0\n",
      "  Using cached scipy-1.10.0-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "INFO: pip is looking at multiple versions of scikit-image to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scikit-image==0.19.3\n",
      "  Using cached scikit_image-0.19.3-cp310-cp310-win_amd64.whl (12.0 MB)\n",
      "INFO: pip is looking at multiple versions of rsa to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rsa==4.9\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "INFO: pip is looking at multiple versions of rfc3986-validator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rfc3986-validator==0.1.1\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "INFO: pip is looking at multiple versions of rfc3339-validator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rfc3339-validator==0.1.4\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "INFO: pip is looking at multiple versions of requests-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests-oauthlib==1.3.1\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests==2.21.0\n",
      "  Using cached requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
      "INFO: pip is looking at multiple versions of qtpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting QtPy==2.3.0\n",
      "  Using cached QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
      "INFO: pip is looking at multiple versions of qtconsole to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting qtconsole==5.4.0\n",
      "  Using cached qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
      "INFO: pip is looking at multiple versions of pyzmq to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyzmq==25.0.0\n",
      "  Using cached pyzmq-25.0.0-cp310-cp310-win_amd64.whl (969 kB)\n",
      "INFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyYAML==6.0\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "INFO: pip is looking at multiple versions of pywinpty to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pywinpty==2.0.10\n",
      "  Using cached pywinpty-2.0.10-cp310-none-win_amd64.whl (1.4 MB)\n",
      "INFO: pip is looking at multiple versions of pywin32 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pywin32==305\n",
      "  Using cached pywin32-305-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "INFO: pip is looking at multiple versions of pywavelets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyWavelets==1.4.1\n",
      "  Using cached PyWavelets-1.4.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "INFO: pip is looking at multiple versions of pytz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytz==2022.7.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "INFO: pip is looking at multiple versions of python-json-logger to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-json-logger==2.0.4\n",
      "  Using cached python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
      "INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-dateutil==2.8.2\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "INFO: pip is looking at multiple versions of pyrsistent to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyrsistent==0.19.3\n",
      "  Using cached pyrsistent-0.19.3-cp310-cp310-win_amd64.whl (62 kB)\n",
      "INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyparsing==3.0.9\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "INFO: pip is looking at multiple versions of pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Pygments==2.14.0\n",
      "  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "INFO: pip is looking at multiple versions of pycparser to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "INFO: pip is looking at multiple versions of pycocotools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pycocotools==2.0.6\n",
      "  Using cached pycocotools-2.0.6-cp310-cp310-win_amd64.whl\n",
      "INFO: pip is looking at multiple versions of pyasn1-modules to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyasn1-modules==0.2.8\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "INFO: pip is looking at multiple versions of pyasn1 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyasn1==0.4.8\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "INFO: pip is looking at multiple versions of pure-eval to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting psutil==5.9.4\n",
      "  Using cached psutil-5.9.4-cp36-abi3-win_amd64.whl (252 kB)\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf==3.19.6\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "INFO: pip is looking at multiple versions of prompt-toolkit to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting prompt-toolkit==3.0.36\n",
      "  Using cached prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
      "INFO: pip is looking at multiple versions of prometheus-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting prometheus-client==0.16.0\n",
      "  Using cached prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
      "INFO: pip is looking at multiple versions of proglog to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting proglog==0.1.10\n",
      "  Using cached proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "INFO: pip is looking at multiple versions of portpicker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting portpicker==1.2.0\n",
      "  Using cached portpicker-1.2.0-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of portalocker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting portalocker==2.7.0\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of platformdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting platformdirs==3.0.0\n",
      "  Using cached platformdirs-3.0.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of pillow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Pillow==9.4.0\n",
      "  Using cached Pillow-9.4.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "INFO: pip is looking at multiple versions of pickleshare to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pickleshare==0.7.5\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "INFO: pip is looking at multiple versions of pathspec to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pathspec==0.11.0\n",
      "  Using cached pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
      "INFO: pip is looking at multiple versions of parso to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting parso==0.8.3\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "INFO: pip is looking at multiple versions of pandocfilters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandocfilters==1.5.0\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging==23.0\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of opt-einsum to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opt-einsum==3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python==4.7.0.68\n",
      "  Using cached opencv_python-4.7.0.68-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-contrib-python==4.7.0.68\n",
      "  Using cached opencv_contrib_python-4.7.0.68-cp37-abi3-win_amd64.whl (44.9 MB)\n",
      "INFO: pip is looking at multiple versions of omegaconf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting omegaconf==2.3.0\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "INFO: pip is looking at multiple versions of oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting oauthlib==3.2.2\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy==1.24.2\n",
      "  Using cached numpy-1.24.2-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "INFO: pip is looking at multiple versions of notebook-shim to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook_shim==0.2.2\n",
      "  Using cached notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook==6.5.2\n",
      "  Using cached notebook-6.5.2-py3-none-any.whl (439 kB)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx==3.0\n",
      "  Using cached networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "INFO: pip is looking at multiple versions of nest-asyncio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nest-asyncio==1.5.6\n",
      "  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of nbformat to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbformat==5.7.3\n",
      "  Using cached nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
      "INFO: pip is looking at multiple versions of nbconvert to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbconvert==7.2.9\n",
      "  Using cached nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
      "INFO: pip is looking at multiple versions of nbclient to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbclient==0.7.2\n",
      "  Using cached nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
      "INFO: pip is looking at multiple versions of nbclassic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbclassic==0.5.1\n",
      "  Using cached nbclassic-0.5.1-py3-none-any.whl (10.0 MB)\n",
      "INFO: pip is looking at multiple versions of natsort to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting natsort==8.2.0\n",
      "  Using cached natsort-8.2.0-py3-none-any.whl (37 kB)\n",
      "INFO: pip is looking at multiple versions of mypy-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mypy-extensions==1.0.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "INFO: pip is looking at multiple versions of moviepy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting moviepy==1.0.3\n",
      "  Using cached moviepy-1.0.3-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of mistune to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mistune==2.0.5\n",
      "  Using cached mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib-inline to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib-inline==0.1.6\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib==3.6.3\n",
      "  Using cached matplotlib-3.6.3-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting MarkupSafe==2.1.2\n",
      "  Using cached MarkupSafe-2.1.2-cp310-cp310-win_amd64.whl (16 kB)\n",
      "INFO: pip is looking at multiple versions of markdown to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Markdown==3.4.1\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "INFO: pip is looking at multiple versions of libclang to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting libclang==15.0.6.1\n",
      "  Using cached libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kiwisolver==1.4.4\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "INFO: pip is looking at multiple versions of keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras==2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab-widgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab-widgets==3.0.5\n",
      "  Using cached jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab-pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab-pygments==0.2.2\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server-terminals to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server_terminals==0.4.4\n",
      "  Using cached jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server==2.2.1\n",
      "  Using cached jupyter_server-2.2.1-py3-none-any.whl (365 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_core==5.2.0\n",
      "  Using cached jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_client==8.0.2\n",
      "  Using cached jupyter_client-8.0.2-py3-none-any.whl (103 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-events to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-events==0.6.3\n",
      "  Using cached jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-console to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-console==6.5.0\n",
      "  Using cached jupyter_console-6.5.0-py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter==1.0.0\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonschema==4.17.3\n",
      "  Using cached jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "INFO: pip is looking at multiple versions of jsonpointer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonpointer==2.3\n",
      "  Using cached jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Jinja2==3.1.2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jedi==0.18.2\n",
      "  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of isoduration to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting isoduration==20.11.0\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipywidgets==8.0.4\n",
      "  Using cached ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
      "INFO: pip is looking at multiple versions of ipython-genutils to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython-genutils==0.2.0\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython==8.10.0\n",
      "  Using cached ipython-8.10.0-py3-none-any.whl (784 kB)\n",
      "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipykernel==6.21.1\n",
      "  Using cached ipykernel-6.21.1-py3-none-any.whl (149 kB)\n",
      "INFO: pip is looking at multiple versions of iopath to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting iopath==0.1.9\n",
      "  Using cached iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "INFO: pip is looking at multiple versions of imageio-ffmpeg to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting imageio-ffmpeg==0.4.8\n",
      "  Using cached imageio_ffmpeg-0.4.8-py3-none-win_amd64.whl (22.6 MB)\n",
      "INFO: pip is looking at multiple versions of imageio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting imageio==2.25.0\n",
      "  Using cached imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
      "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting idna==2.8\n",
      "  Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "INFO: pip is looking at multiple versions of hydra-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting hydra-core==1.3.1\n",
      "  Using cached hydra_core-1.3.1-py3-none-any.whl (154 kB)\n",
      "INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h5py==3.8.0\n",
      "  Using cached h5py-3.8.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio==1.51.1\n",
      "  Using cached grpcio-1.51.1-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "INFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-pasta==0.2.0\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth-oauthlib==0.4.6\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth==1.4.2\n",
      "  Using cached google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n",
      "INFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fvcore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fvcore==0.1.5.post20221221\n",
      "  Using cached fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of fqdn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fqdn==1.5.1\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fonttools==4.38.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "INFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting flatbuffers==23.1.21\n",
      "  Using cached flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of fer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fer==22.5.0\n",
      "  Using cached fer-22.5.0-py3-none-any.whl (1.5 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of fastjsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fastjsonschema==2.16.2\n",
      "  Using cached fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
      "INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting facenet-pytorch==2.5.2\n",
      "  Using cached facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "INFO: pip is looking at multiple versions of executing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting executing==1.2.0\n",
      "  Using cached executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of entrypoints to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting entrypoints==0.4\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting defusedxml==0.7.1\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting debugpy==1.6.6\n",
      "  Using cached debugpy-1.6.6-cp310-cp310-win_amd64.whl (4.8 MB)\n",
      "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cycler==0.11.0\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy==1.0.7\n",
      "  Using cached contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
      "INFO: pip is looking at multiple versions of comm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting comm==0.1.2\n",
      "  Using cached comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
      "INFO: pip is looking at multiple versions of colorthief to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting colorthief==0.2.1\n",
      "  Using cached colorthief-0.2.1-py2.py3-none-any.whl (6.1 kB)\n",
      "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting colorama==0.4.6\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cloudpickle==2.2.1\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting click==8.1.3\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting charset-normalizer==3.0.1\n",
      "  Using cached charset_normalizer-3.0.1-cp310-cp310-win_amd64.whl (96 kB)\n",
      "INFO: pip is looking at multiple versions of chardet to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chardet==3.0.4\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of cffi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cffi==1.15.1\n",
      "  Using cached cffi-1.15.1-cp310-cp310-win_amd64.whl (179 kB)\n",
      "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting certifi==2022.12.7\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "INFO: pip is looking at multiple versions of cachetools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cachetools==5.3.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of bleach to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bleach==6.0.0\n",
      "  Using cached bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "INFO: pip is looking at multiple versions of black to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting black==23.1.0\n",
      "  Using cached black-23.1.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "INFO: pip is looking at multiple versions of beautifulsoup4 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting beautifulsoup4==4.11.2\n",
      "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting backcall==0.2.0\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting attrs==22.2.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "INFO: pip is looking at multiple versions of asttokens to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting asttokens==2.2.1\n",
      "  Using cached asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of arrow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting arrow==1.2.3\n",
      "  Using cached arrow-1.2.3-py3-none-any.whl (66 kB)\n",
      "INFO: pip is looking at multiple versions of argon2-cffi-bindings to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting argon2-cffi-bindings==21.2.0\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "INFO: pip is looking at multiple versions of argon2-cffi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting argon2-cffi==21.3.0\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of anyio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting anyio==3.6.2\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "INFO: pip is looking at multiple versions of antlr4-python3-runtime to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting antlr4-python3-runtime==4.9.3\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting absl-py==1.4.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested google-auth==1.4.2\n",
      "    google-auth-oauthlib 0.4.6 depends on google-auth>=1.0.0\n",
      "    tensorboard 2.11.2 depends on google-auth<3 and >=1.6.3\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install -r requirements.txt (line 40), google-auth==1.4.2 and tensorboard==2.11.2 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r requirements.txt\n",
    "#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' #needs to be installed manually if needed; remove ObjectDetection class if not needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, os, math, pathlib, random, re, sys, statistics, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch, torchvision\n",
    "import pylab\n",
    "#import detectron2\n",
    "\n",
    "from natsort import natsorted, ns\n",
    "from colorthief import ColorThief\n",
    "from fer import FER\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io #scikit-image\n",
    "\n",
    "from torch.autograd import Variable as V\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "#from detectron2.utils.logger import setup_logger\n",
    "#from detectron2 import model_zoo\n",
    "#from detectron2.engine import DefaultPredictor\n",
    "#from detectron2.config import get_cfg\n",
    "#from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "#from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup logger for detectron2\n",
    "#setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "\n",
    "  def __init__(self):\n",
    "    with open(\"./config.json\", \"rb\") as file:\n",
    "      self.config = json.load(file)\n",
    "    \n",
    "    self.inputRoot = pathlib.Path(self.config[\"inputRoot\"])\n",
    "    self.outputRoot = pathlib.Path(self.config[\"outputRoot\"])\n",
    "\n",
    "  def getInputRoot(self):\n",
    "    return self.config[\"inputRoot\"] + \"\\\\\"\n",
    "\n",
    "  def getOutputRoot(self):\n",
    "    return self.config[\"outputRoot\"] + \"\\\\\"\n",
    "\n",
    "  def getGameNames(self):\n",
    "    return [gameName for gameName in self.config[\"games\"]]\n",
    "\n",
    "  def getMethodNames(self):\n",
    "    return self.config[\"methods\"]\n",
    "\n",
    "  def checkInputFolder(self):\n",
    "    \"\"\"\n",
    "      Checks if the base input path has directories for each game. Also checks if each directory has game images, otherwise prints warnings.\n",
    "      Not checking might result in an error because there is no folder to write to. This methods raises expections if folders are missing\n",
    "      and warns if there are folders or files that are not defined in config.json.\n",
    "    \"\"\"\n",
    "    gameNames = self.getGameNames()\n",
    "    \n",
    "    for gameFolder in self.inputRoot.iterdir():\n",
    "      if gameFolder.is_dir() and gameFolder.name in gameNames:\n",
    "        gameNames.remove(gameFolder.name)\n",
    "\n",
    "        if not any(gameFolder.iterdir()):\n",
    "          print(f\"WARNING: {gameFolder} contains no game images\")\n",
    "      else:\n",
    "        print(f\"WARNING: {gameFolder} not in games or not a directory\")\n",
    "\n",
    "    if len(gameNames) != 0:\n",
    "      raise Exception(f\"there are the following missing folders: {', '.join(gameNames)}\")\n",
    "\n",
    "    print(\"Input folder is ok.\")\n",
    "  \n",
    "  def checkOutputFolder(self):\n",
    "    \"\"\"\n",
    "      Checks if the base output path has directories for each CV method. Also checks if each directory has subfolders for each game.\n",
    "      Not checking might result in an error because there is no folder to write to. This methods raises expections if folders are missing\n",
    "      and warns if there are folders or files that are not defined in config.json. Prints warning if folders contain files that might\n",
    "      be overwritten.\n",
    "    \"\"\"\n",
    "    methodNames = self.getMethodNames()\n",
    "    \n",
    "    for methodFolder in self.outputRoot.iterdir():\n",
    "      if methodFolder.is_dir() and methodFolder.name in methodNames:\n",
    "        methodNames.remove(methodFolder.name)\n",
    "\n",
    "        games = pathlib.Path(methodFolder)\n",
    "        gameNames = self.getGameNames()\n",
    "\n",
    "        for gameFolder in games.iterdir():\n",
    "          if gameFolder.is_dir() and gameFolder.name in gameNames:\n",
    "            gameNames.remove(gameFolder.name)\n",
    "\n",
    "            if any(gameFolder.iterdir()):\n",
    "              print(f\"WARNING: {gameFolder} contains files\")  \n",
    "          else:\n",
    "            print(f\"WARNING: {gameFolder} not in games or not a directory\")\n",
    "          pass\n",
    "\n",
    "        if len(gameNames) != 0:\n",
    "          raise Exception(f\"there are the following missing folders in {methodFolder}: {', '.join(gameNames)}\")\n",
    "\n",
    "      else:\n",
    "        print(f\"WARNING: {methodFolder} not in methods or not a directory\")\n",
    "\n",
    "    if len(methodNames) != 0:\n",
    "      raise Exception(f\"there are the following missing folders: {', '.join(methodNames)}\")\n",
    "\n",
    "    print(\"Output folder is ok.\")\n",
    "\n",
    "  def getFileLength(self):\n",
    "    numGames = 0\n",
    "    gameNames = self.getGameNames()\n",
    "    \n",
    "    for gameFolder in self.inputRoot.iterdir():\n",
    "      if gameFolder.is_dir() and gameFolder.name in gameNames:\n",
    "        numGames += len(list(gameFolder.iterdir()))\n",
    "    \n",
    "    return numGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGender:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"AgeGender\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "    self.outputPathImages = f\"{self.outputPathCSV}\\\\{self.gameName}\\\\\"\n",
    "  \n",
    "    # Defined the model files\n",
    "    self.FACE_PROTO = \"./models/opencv_face_detector.pbtxt\"\n",
    "    self.FACE_MODEL = \"./models/opencv_face_detector_uint8.pb\"\n",
    "    self.AGE_PROTO = \"./models/age_deploy.prototxt\"\n",
    "    self.AGE_MODEL = \"./models/age_net.caffemodel\"\n",
    "    self.GENDER_PROTO = \"./models/gender_deploy.prototxt\"\n",
    "    self.GENDER_MODEL = \"./models/gender_net.caffemodel\"\n",
    "\n",
    "    # Load network\n",
    "    self.FACE_NET = cv2.dnn.readNet(self.FACE_MODEL, self.FACE_PROTO)\n",
    "    self.AGE_NET = cv2.dnn.readNet(self.AGE_MODEL, self.AGE_PROTO)\n",
    "    self.GENDER_NET = cv2.dnn.readNet(self.GENDER_MODEL, self.GENDER_PROTO)\n",
    "\n",
    "    self.MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "    self.AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "    self.GENDER_LIST = [\"Male\", \"Female\"]\n",
    "\n",
    "    self.box_padding = 20\n",
    "\n",
    "    self.frameName = []\n",
    "    self.person = []\n",
    "    self.boxFace = []\n",
    "    self.gen = []\n",
    "    self.gender_conf = []\n",
    "    self.ages = []\n",
    "    self.age_conf = []\n",
    "\n",
    "  def get_face_box (self, net, frame, conf_threshold = 0.5):\n",
    "    frame_copy = frame.copy()\n",
    "    frame_height = frame_copy.shape[0]\n",
    "    frame_width = frame_copy.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frame_copy, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "      confidence = detections[0, 0, i, 2]\n",
    "\n",
    "      if confidence > conf_threshold:\n",
    "        x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "        y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "        x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "        y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), int(round(frame_height / 150)), 8)\n",
    "\n",
    "    return frame_copy, boxes\n",
    "\n",
    "  def handleNextImage(self, fileName, image):\n",
    "    resized_image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    frame = resized_image.copy()\n",
    "    frame_face, boxes = self.get_face_box(self.FACE_NET, frame)\n",
    "\n",
    "    count = 0\n",
    "    for box in boxes:\n",
    "      self.frameName.append(fileName)\n",
    "      self.person.append(count)\n",
    "      self.boxFace.append(box)\n",
    "      face = frame[max(0, box[1] - self.box_padding):min(box[3] + self.box_padding, frame.shape[0] - 1), \\\n",
    "        max(0, box[0] - self.box_padding):min(box[2] + self.box_padding, frame.shape[1] - 1)]\n",
    "\n",
    "      blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), self.MODEL_MEAN_VALUES, swapRB = False)\n",
    "      self.GENDER_NET.setInput(blob)\n",
    "      gender_predictions = self.GENDER_NET.forward()\n",
    "      gender = self.GENDER_LIST[gender_predictions[0].argmax()]\n",
    "      self.gen.append(gender)\n",
    "      self.gender_conf.append(gender_predictions[0].max())\n",
    "\n",
    "      self.AGE_NET.setInput(blob)\n",
    "      age_predictions = self.AGE_NET.forward()\n",
    "      age = self.AGE_LIST[age_predictions[0].argmax()]\n",
    "      self.ages.append(age)\n",
    "      self.age_conf.append(age_predictions[0].max())\n",
    "\n",
    "      label = \"{},{}\".format(gender, age)\n",
    "      cv2.putText(frame_face, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "      cv2.putText(frame_face, str(count), (box[0] + 2, box[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n",
    "\n",
    "      count += 1\n",
    "\n",
    "    #only saves an image if age/gender was found\n",
    "    if len(boxes) > 0:\n",
    "      cv2.resize(frame_face, (640, 480))\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{fileName}\", frame_face)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    if len(self.frameName) > 0:\n",
    "      df = pd.DataFrame(list(zip(self.frameName, self.person, self.boxFace, self.gen, self.gender_conf, self.ages, self.age_conf)))\n",
    "      df.columns = ['Name', 'person', 'box', 'gender', 'gender_conf', 'age', 'age_conf']\n",
    "      df.to_csv(f\"{self.outputPathCSV}{self.gameName}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrightnessAnalyzer:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"Brightness\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "    \n",
    "    self.brightness_dict = {}\n",
    "    self.brightness_values_dict = {}\n",
    "    self.statistic_result_dict = {}\n",
    "\n",
    "  def handleNextImage(self, fileName, image):\n",
    "    greyscale_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_brightness = greyscale_img.mean()/255\n",
    "\n",
    "    self.brightness_values_dict[fileName] = img_brightness\n",
    "\n",
    "    self.brightness_dict[fileName] = []\n",
    "    self.brightness_dict[fileName].append(round(img_brightness, 2))\n",
    "    self.brightness_dict[fileName].append(fileName)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    mean_brightness = sum(self.brightness_values_dict.values()) / len(self.brightness_dict)\n",
    "    sd_brightness = statistics.stdev(self.brightness_values_dict.values())\n",
    "    median_brightness = statistics.stdev(self.brightness_values_dict.values())\n",
    "    min_brightness = min(self.brightness_values_dict.values())\n",
    "    max_brightness = max(self.brightness_values_dict.values())\n",
    "\n",
    "    statistic_result_dict = {}\n",
    "    statistic_result_dict[\"min\"] = []\n",
    "    statistic_result_dict[\"min\"].append(round(min_brightness, 2))\n",
    "    statistic_result_dict[\"median\"] = []\n",
    "    statistic_result_dict[\"median\"].append(round(median_brightness, 2))\n",
    "    statistic_result_dict[\"mean\"] = []\n",
    "    statistic_result_dict[\"mean\"].append(round(mean_brightness, 2))\n",
    "    statistic_result_dict[\"sd\"] = []\n",
    "    statistic_result_dict[\"sd\"].append(round(sd_brightness, 2))\n",
    "    statistic_result_dict[\"max\"] = []\n",
    "    statistic_result_dict[\"max\"].append(round(max_brightness, 2))\n",
    "\n",
    "    dataBrightness = pd.DataFrame.from_dict(self.brightness_dict, orient='index', columns=[\"brightness_value\", \"frame\"])\n",
    "    dataResults = pd.DataFrame.from_dict(statistic_result_dict)\n",
    "\n",
    "    cols = dataBrightness.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataBrightness = dataBrightness[cols]\n",
    "\n",
    "    dataBrightness.to_csv(f\"{self.outputPathCSV}{self.gameName}_Brightness.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "    cols = dataResults.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataResults = dataResults[cols]\n",
    "    \n",
    "    dataResults.to_csv(f\"{self.outputPathCSV}{self.gameName}_Statistics.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "  def generateGreyScaleGraph(self):\n",
    "    brightness_values_list = self.brightness_values_dict.items()\n",
    "\n",
    "    x, y = zip(*brightness_values_list)\n",
    "\n",
    "    plt.plot(y, color=\"navy\")\n",
    "    plt.xlabel(\"frame\")\n",
    "    plt.ylabel(\"greyscale value\")\n",
    "\n",
    "    #plt.title(\"Grayscale values for \" + self.gameName , fontsize= 15, pad=20)\n",
    "    #plt.legend([\"greyscale value 0 = complete black image\\ngreyscale value 1 = complete white image\"])\n",
    "\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.gameName}_Graph.eps\", format='eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomColorThief(ColorThief):\n",
    "  def __init__(self, image):\n",
    "    self.image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "class DominantColor:\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"DominantColor\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "\n",
    "    self.dominant_color_arr = []\n",
    "    self.frameNames = []\n",
    "\n",
    "  def handleNextImage(self, frameName, image):\n",
    "    ct_frame = CustomColorThief(image)\n",
    "    # change quality to \"2\" to get the second most dominat color\n",
    "    dominant_color_of_ct_frame = ct_frame.get_color(quality=1)\n",
    "    self.dominant_color_arr.append(dominant_color_of_ct_frame)\n",
    "    self.frameNames.append(frameName)\n",
    "\n",
    "  def generateColorBars(self):\n",
    "    plt.ioff()\n",
    "    plt.imshow([[self.dominant_color_arr[i] for i in range(len(self.dominant_color_arr))]], extent=[0,len(self.dominant_color_arr),0,1], aspect='auto')\n",
    "    plt.ion()\n",
    "\n",
    "    # axis adjustments\n",
    "    plt.xlabel(\"frame\")\n",
    "    plt.ylabel(\"dominant color\")\n",
    "    plt.yticks([])\n",
    "\n",
    "    # enable the line if you want your plot to have a title\n",
    "    #plt.title(\"DominantColorBarcode for \" + self.gameName, fontsize= 15, pad=20)\n",
    "\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.gameName}_dominant_color_for_each_frame.eps\", format='eps')\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_dominant_color_for_each_frame.svg\", format='svg')\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_dominant_color_for_each_frame.png\")\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_dominant_color_for_each_frame.jpg\")\n",
    "\n",
    "    plt.close()\n",
    "  \n",
    "  def dataToCSV(self):\n",
    "    dominant_color_dict = {}\n",
    "\n",
    "    for idx, frame_name in enumerate(self.dominant_color_arr):\n",
    "      dominant_color_dict[frame_name] = []\n",
    "      dominant_color_dict[frame_name].append(self.dominant_color_arr[idx])\n",
    "      dominant_color_dict[frame_name].append(self.frameNames[idx])\n",
    "\n",
    "    dominant_color_row_data = pd.DataFrame.from_dict(dominant_color_dict, orient='index', columns=[\"RGB\", \"frame\"])\n",
    "    \n",
    "    cols_row_data = dominant_color_row_data.columns.tolist()\n",
    "    cols_row_data = cols_row_data[-1:] + cols_row_data[:-1]\n",
    "    dominant_color_row_data = dominant_color_row_data[cols_row_data]\n",
    "    \n",
    "    dominant_color_row_data.to_csv(f\"{self.outputPathCSV}{self.gameName}_dominant_color_row_data.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageColor:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"AverageColor\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "\n",
    "    self.averageColorArr = []\n",
    "    self.frameNames = []\n",
    "\n",
    "  def handleNextImage(self, frameName, image):\n",
    "    average_color_row = np.average(image, axis=0)\n",
    "    average_color = np.average(average_color_row, axis=0)\n",
    "\n",
    "    average_color_tuple = tuple(average_color)\n",
    "\n",
    "    self.averageColorArr.append(average_color_tuple)\n",
    "    self.frameNames.append(frameName)\n",
    "\n",
    "  def generateColorBars(self):\n",
    "    self.averageColorArr = tuple(tuple(map(int, tup)) for tup in self.averageColorArr)\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.imshow([[self.averageColorArr[i] for i in range(len(self.averageColorArr))]], extent=[0,len(self.averageColorArr),0,1], aspect='auto')\n",
    "    plt.ioff()\n",
    "\n",
    "    # axis adjustments\n",
    "    plt.xlabel(\"frame\")\n",
    "    plt.ylabel(\"average color\")\n",
    "    plt.yticks([])\n",
    "\n",
    "    # enable the line if you want your plot to have a title\n",
    "    #plt.title(\"AverageColorBarcode for \" + self.gameName, fontsize= 15, pad=20)\n",
    "\n",
    "    plt.savefig(f\"{self.outputPathCSV}{self.gameName}_average_color_for_each_frame.eps\", format='eps')\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_average_color_for_each_frame.svg\", format='svg')\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_average_color_for_each_frame.png\")\n",
    "    #plt.savefig(f\"{self.outputPathCSV}{self.gameName}_average_color_for_each_frame.jpg\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    average_color_dict = {}\n",
    "\n",
    "    for idx, frame_name in enumerate(self.averageColorArr):\n",
    "      average_color_dict[frame_name] = []\n",
    "      average_color_dict[frame_name].append(self.averageColorArr[idx])\n",
    "      average_color_dict[frame_name].append(self.frameNames[idx])\n",
    "\n",
    "    average_color_row_data = pd.DataFrame.from_dict(average_color_dict, orient='index', columns=[\"RGB\", \"frame\"])\n",
    "    \n",
    "    cols_row_data = average_color_row_data.columns.tolist()\n",
    "    cols_row_data = cols_row_data[-1:] + cols_row_data[:-1]\n",
    "    average_color_row_data = average_color_row_data[cols_row_data]\n",
    "    \n",
    "    average_color_row_data.to_csv(f\"{self.outputPathCSV}{self.gameName}_average_color_row_data.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDetection:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"Emotion\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "    self.outputPathImages = f\"{self.outputPathCSV}\\\\{self.gameName}\\\\\"\n",
    "\n",
    "    self.detectorMT = FER(mtcnn=True)\n",
    "\n",
    "    self.emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    self.categories = ['box', 'emotions']\n",
    "\n",
    "    self.frame = []\n",
    "    self.person = []\n",
    "    self.box = []\n",
    "    self.angry = []\n",
    "    self.disgust = []\n",
    "    self.fear = []\n",
    "    self.happy = []\n",
    "    self.sad = []\n",
    "    self.suprise = []\n",
    "    self.neutral = []\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    prediction = self.detectorMT.detect_emotions(frameData)\n",
    "\n",
    "    for n in range(len(prediction)):\n",
    "      bbox = prediction[n][self.categories[0]]\n",
    "      img = cv2.rectangle(frameData, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]),(0, 255, 0), 1,)\n",
    "      cv2.putText(img, str(n), (bbox[0] + 2, bbox[1] + 15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),1,cv2.LINE_AA, )\n",
    "      self.frame.append(frameName)\n",
    "      self.person.append(n)\n",
    "      self.box.append(bbox)\n",
    "      self.angry.append(prediction[n][self.categories[1]][self.emotions[0]])\n",
    "      self.disgust.append(prediction[n][self.categories[1]][self.emotions[1]])\n",
    "      self.fear.append(prediction[n][self.categories[1]][self.emotions[2]])\n",
    "      self.happy.append(prediction[n][self.categories[1]][self.emotions[3]])\n",
    "      self.sad.append(prediction[n][self.categories[1]][self.emotions[4]])\n",
    "      self.suprise.append(prediction[n][self.categories[1]][self.emotions[5]])\n",
    "      self.neutral.append(prediction[n][self.categories[1]][self.emotions[6]])\n",
    "\n",
    "    if len(prediction) > 0:\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{frameName}\", img)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    df = pd.DataFrame(list(zip(self.frame, self.person, self.box, self.angry, self.disgust, self.fear, self.happy, self.sad, self.suprise, self.neutral)))\n",
    "    df.columns = ['Name', 'person', 'box', 'angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    df.to_csv(f\"{self.outputPathCSV}{self.gameName}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationDetection:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"Location\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "    self.outputPathImages = f\"{self.outputPathCSV}\\\\{self.gameName}\\\\\"\n",
    "\n",
    "    self.CATEGORIES_PLACES = \"./models/categories_places365.txt\"\n",
    "    self.IO_PLACES = \"./models/IO_places365.txt\"\n",
    "    self.LABELS_SUNATTRIBUTE = \"./models/labels_sunattribute.txt\"\n",
    "    self.SCENE_ATTRIBUTE_NPY = \"./models/W_sceneattribute_wideresnet18.npy\"\n",
    "\n",
    "    self.classes = None\n",
    "    self.labels_IO = None\n",
    "    self.labels_attribute = None\n",
    "    self.W_attribute = None\n",
    "\n",
    "    self.features_blobs = []\n",
    "    self.load_labels()\n",
    "    self.model = self.load_model()\n",
    "    self.tf = self.returnTF()\n",
    "\n",
    "    self.params = list(self.model.parameters())\n",
    "    self.weight_softmax = self.params[-2].data.numpy()\n",
    "    self.weight_softmax[self.weight_softmax<0] = 0\n",
    "\n",
    "    self.frame_names = []\n",
    "    self.io_score = []\n",
    "    self.io = []\n",
    "    self.prob_cat_1 = []\n",
    "    self.cat_1 = []\n",
    "    self.prob_cat_2 = []\n",
    "    self.cat_2 = []\n",
    "    self.prob_cat_3 = []\n",
    "    self.cat_3 = []\n",
    "    self.prob_cat_4 = []\n",
    "    self.cat_4 = []\n",
    "    self.prob_cat_5 = []\n",
    "    self.cat_5 = []\n",
    "\n",
    "  def load_labels(self):\n",
    "    c = list()\n",
    "    with open(self.CATEGORIES_PLACES) as class_file:\n",
    "      for line in class_file:\n",
    "        c.append(line.strip().split(' ')[0][3:])\n",
    "    self.classes = tuple(c)\n",
    "\n",
    "    with open(self.IO_PLACES) as f:\n",
    "      lines = f.readlines()\n",
    "      labels_IO = []\n",
    "      for line in lines:\n",
    "        items = line.rstrip().split()\n",
    "        labels_IO.append(int(items[-1]) -1) # 0 is indoor, 1 is outdoor\n",
    "    self.labels_IO = np.array(labels_IO)\n",
    "\n",
    "    with open(self.LABELS_SUNATTRIBUTE) as f:\n",
    "      lines = f.readlines()\n",
    "      self.labels_attribute = [item.rstrip() for item in lines]\n",
    "\n",
    "    self.W_attribute = np.load(self.SCENE_ATTRIBUTE_NPY)\n",
    "\n",
    "  def load_model(self):#TODO\n",
    "    # this model has a last conv feature map as 14x14\n",
    "    import models.wideresnet as wideresnet\n",
    "    model = wideresnet.resnet18(num_classes=365)\n",
    "    checkpoint = torch.load(\"./models/wideresnet18_places365.pth.tar\", map_location=lambda storage, loc: storage)\n",
    "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # hacky way to deal with the upgraded batchnorm2D and avgpool layers...\n",
    "    for i, (name, module) in enumerate(model._modules.items()):\n",
    "        module = self.recursion_change_bn(model)\n",
    "    model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # the following is deprecated, everything is migrated to python36\n",
    "\n",
    "    ## if you encounter the UnicodeDecodeError when use python3 to load the model, add the following line will fix it. Thanks to @soravux\n",
    "    #from functools import partial\n",
    "    #import pickle\n",
    "    #pickle.load = partial(pickle.load, encoding=\"latin1\")\n",
    "    #pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")\n",
    "    #model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle)\n",
    "\n",
    "    model.eval()\n",
    "    # hook the feature extractor\n",
    "    features_names = ['layer4','avgpool'] # this is the last conv layer of the resnet\n",
    "    for name in features_names:\n",
    "        model._modules.get(name).register_forward_hook(self.hook_feature)\n",
    "    return model\n",
    "\n",
    "  # hacky way to deal with the Pytorch 1.0 update\n",
    "  def recursion_change_bn(self, module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "      module.track_running_stats = 1\n",
    "    else:\n",
    "      for i, (name, module1) in enumerate(module._modules.items()):\n",
    "        module1 = self.recursion_change_bn(module1)\n",
    "    return module\n",
    "\n",
    "  def hook_feature(self, module, input, output):\n",
    "    self.features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
    "\n",
    "  def returnCAM(self, feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "  def returnTF(self):\n",
    "  # load the image transformer\n",
    "    tf = trn.Compose([\n",
    "      trn.Resize((224,224)),\n",
    "      trn.ToTensor(),\n",
    "      trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return tf\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    self.frame_names.append(frameName)\n",
    "    imageCopy = frameData.copy()\n",
    "    image = Image.fromarray(cv2.cvtColor(frameData, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    input_img = V(self.tf(image).unsqueeze(0))   \n",
    "    logit = self.model.forward(input_img)\n",
    "    h_x = F.softmax(logit, 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy() \n",
    "\n",
    "    io_image = np.mean(self.labels_IO[idx[:10]])\n",
    "    self.io_score.append(io_image)\n",
    "    if io_image < 0.5:\n",
    "      self.io.append(\"indoor\")\n",
    "    else:\n",
    "      self.io.append(\"outdoor\")\n",
    "    \n",
    "    self.prob_cat_1.append(probs[0])\n",
    "    self.cat_1.append(self.classes[idx[0]])\n",
    "    self.prob_cat_2.append(probs[1])\n",
    "    self.cat_2.append(self.classes[idx[1]])\n",
    "    self.prob_cat_3.append(probs[2])\n",
    "    self.cat_3.append(self.classes[idx[2]])\n",
    "    self.prob_cat_4.append(probs[3])\n",
    "    self.cat_4.append(self.classes[idx[3]])\n",
    "    self.prob_cat_5.append(probs[4])\n",
    "    self.cat_5.append(self.classes[idx[4]])\n",
    "\n",
    "    loc1 = \"Location 1: {} ({})\". format(self.cat_1[len(self.cat_1)-1], \"{:.2f}\".format(self.prob_cat_1[len(self.prob_cat_1)-1]))\n",
    "    loc2 = \"Location 2: {} ({})\". format(self.cat_2[len(self.cat_2)-1], \"{:.2f}\".format(self.prob_cat_2[len(self.prob_cat_2)-1]))\n",
    "    loc3 = \"Location 3: {} ({})\". format(self.cat_3[len(self.cat_3)-1], \"{:.2f}\".format(self.prob_cat_3[len(self.prob_cat_3)-1]))\n",
    "    cat = \"Category: {}\".format(self.io[len(self.io)-1])\n",
    "\n",
    "    color = (255,255,255)\n",
    "    cv2.putText(imageCopy, loc1, (20, 40), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, loc2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, loc3, (20, 80), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    cv2.putText(imageCopy, cat, (20, 110), cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA, )\n",
    "    \n",
    "    cv2.imwrite(f\"{self.outputPathImages}{frameName}\", imageCopy)\n",
    "\n",
    "  def dataToCSV(self):\n",
    "    df = pd.DataFrame(list(zip(self.frame_names, self.io_score, self.io, self.prob_cat_1, self.cat_1, self.prob_cat_2, self.cat_2, self.prob_cat_3, self.cat_3, self.prob_cat_4, self.cat_4, self.prob_cat_5, self.cat_5)))\n",
    "    df.columns = ['Name', 'io_score', 'io', 'prob_cat_1', 'cat_1', 'prob_cat_2', 'cat_2', 'prob_cat_3', 'cat_3', 'prob_cat_4', 'cat_4', 'prob_cat_5', 'cat_5']\n",
    "    df.to_csv(f\"{self.outputPathCSV}{self.gameName}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "\n",
    "  def __init__(self, gameName, outputPath):\n",
    "    self.method = \"ObjectDetection\"\n",
    "    self.gameName = gameName\n",
    "    self.outputPathCSV = f\"{outputPath}{self.method}\\\\\"\n",
    "    self.outputPathImages = f\"{self.outputPathCSV}\\\\{self.gameName}\\\\\"\n",
    "\n",
    "    self.threshold = 0.5\n",
    "    self.createImages = True\n",
    "    self.predictor = None\n",
    "    self.cfg = None\n",
    "    self.classDict = None\n",
    "    self.allDic = []\n",
    "    \n",
    "    self.checkGPU()\n",
    "    self.loadClasses()\n",
    "   \n",
    "  def checkGPU():\n",
    "    # If there's a GPU available...\n",
    "    if torch.cuda.is_available():    \n",
    "        # Tell PyTorch to use the GPU.    \n",
    "        device = torch.device(\"cuda\")\n",
    "\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "    # If not...\n",
    "    else:\n",
    "        #device = torch.device(\"cpu\")\n",
    "        raise Exception(\"No GPU available, using the CPU instead.\")\n",
    "\n",
    "  #all underlined methods and classes are imports from detectron\n",
    "  def configDetectron(self):\n",
    "    self.cfg = get_cfg()\n",
    "\n",
    "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "    self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.threshold  # set threshold for this model\n",
    "\n",
    "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "    self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "    self.predictor = DefaultPredictor(cfg)\n",
    "\n",
    "  def loadClasses(self):\n",
    "    self.classDict = {0: u'__background__',\n",
    "      1: u'person',\n",
    "      2: u'bicycle',\n",
    "      3: u'car',\n",
    "      4: u'motorcycle',\n",
    "      5: u'airplane',\n",
    "      6: u'bus',\n",
    "      7: u'train',\n",
    "      8: u'truck',\n",
    "      9: u'boat',\n",
    "      10: u'traffic light',\n",
    "      11: u'fire hydrant',\n",
    "      12: u'stop sign',\n",
    "      13: u'parking meter',\n",
    "      14: u'bench',\n",
    "      15: u'bird',\n",
    "      16: u'cat',\n",
    "      17: u'dog',\n",
    "      18: u'horse',\n",
    "      19: u'sheep',\n",
    "      20: u'cow',\n",
    "      21: u'elephant',\n",
    "      22: u'bear',\n",
    "      23: u'zebra',\n",
    "      24: u'giraffe',\n",
    "      25: u'backpack',\n",
    "      26: u'umbrella',\n",
    "      27: u'handbag',\n",
    "      28: u'tie',\n",
    "      29: u'suitcase',\n",
    "      30: u'frisbee',\n",
    "      31: u'skis',\n",
    "      32: u'snowboard',\n",
    "      33: u'sports ball',\n",
    "      34: u'kite',\n",
    "      35: u'baseball bat',\n",
    "      36: u'baseball glove',\n",
    "      37: u'skateboard',\n",
    "      38: u'surfboard',\n",
    "      39: u'tennis racket',\n",
    "      40: u'bottle',\n",
    "      41: u'wine glass',\n",
    "      42: u'cup',\n",
    "      43: u'fork',\n",
    "      44: u'knife',\n",
    "      45: u'spoon',\n",
    "      46: u'bowl',\n",
    "      47: u'banana',\n",
    "      48: u'apple',\n",
    "      49: u'sandwich',\n",
    "      50: u'orange',\n",
    "      51: u'broccoli',\n",
    "      52: u'carrot',\n",
    "      53: u'hot dog',\n",
    "      54: u'pizza',\n",
    "      55: u'donut',\n",
    "      56: u'cake',\n",
    "      57: u'chair',\n",
    "      58: u'couch',\n",
    "      59: u'potted plant',\n",
    "      60: u'bed',\n",
    "      61: u'dining table',\n",
    "      62: u'toilet',\n",
    "      63: u'tv',\n",
    "      64: u'laptop',\n",
    "      65: u'mouse',\n",
    "      66: u'remote',\n",
    "      67: u'keyboard',\n",
    "      68: u'cell phone',\n",
    "      69: u'microwave',\n",
    "      70: u'oven',\n",
    "      71: u'toaster',\n",
    "      72: u'sink',\n",
    "      73: u'refrigerator',\n",
    "      74: u'book',\n",
    "      75: u'clock',\n",
    "      76: u'vase',\n",
    "      77: u'scissors',\n",
    "      78: u'teddy bear',\n",
    "      79: u'hair drier',\n",
    "      80: u'toothbrush'}\n",
    "\n",
    "  def createBaseDict(self):\n",
    "    baseDict = {v: k for k,v in self.classDict.items()}\n",
    "    del baseDict[\"__background__\"]\n",
    "    for item in baseDict:\n",
    "      baseDict[item] = 0\n",
    "    return baseDict\n",
    "\n",
    "  def getObjectsPerFrame(self, classes):\n",
    "    frameDict = self.createBaseDict()\n",
    "    for item in classes:\n",
    "      classNumber = item.item() + 1\n",
    "      className = self.classDict[classNumber]\n",
    "\n",
    "      frameDict[className] = frameDict[className] + 1\n",
    "\n",
    "    return frameDict\n",
    "\n",
    "  def handleNextImage(self, frameName, frameData):\n",
    "    outputs = self.predictor(frameData)\n",
    "    instances = outputs[\"instances\"].pred_classes\n",
    "    frame = self.getObjectsPerFrame(instances)\n",
    "    frame[\"_id\"] = frameName.split(\".\")[0]\n",
    "\n",
    "    self.allDic.append(frameName)\n",
    "\n",
    "    if self.createImages:\n",
    "      v = Visualizer(frameData[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.0)\n",
    "      out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "      cv2.imwrite(f\"{self.outputPathImages}{frameName}\", out.get_image()[:, :, ::-1])\n",
    "   \n",
    "\n",
    "  def dataToCSV(self):\n",
    "    data = pd.DataFrame.from_dict(self.allDic)\n",
    "    data = data.reindex(sorted(data.columns), axis=1)\n",
    "\n",
    "    #data = data.sort_values(\"_id\")\n",
    "    data[\"sum\"] = data.loc[:, \"airplane\":\"zebra\"].sum(1)\n",
    "    data.to_csv(f\"{self.outputPathCSV}{self.gameName}.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportProgress(count, end, videoName, startTime):\n",
    "  if count == 0:\n",
    "    print(f'\\nStarting to process {videoName}...')\n",
    "  else:\n",
    "    passedTime = time.time() - startTime\n",
    "    progress = count / end\n",
    "    totalTime = passedTime / progress\n",
    "    remainingTime = totalTime - passedTime\n",
    "\n",
    "    hours = math.floor(remainingTime / 3600)\n",
    "    minutes = math.floor((remainingTime - hours * 3600) / 60)\n",
    "    \n",
    "    print(f'\\rProcessing {videoName}: {round(progress * 100, 2)}% -- {hours}hrs {minutes}min remaining.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder is ok.\n",
      "WARNING: C:\\Uni\\dhcv\\output\\AgeGender\\Die_Siedler3 contains files\n",
      "WARNING: C:\\Uni\\dhcv\\output\\AgeGender\\Die_Siedler3.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\AverageColor\\Die_Siedler3_average_color_row_data.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\Brightness\\Die_Siedler3_Brightness.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\Brightness\\Die_Siedler3_Statistics.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\DominantColor\\Die_Siedler3_dominant_color_row_data.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\Emotion\\Die_Siedler3 contains files\n",
      "WARNING: C:\\Uni\\dhcv\\output\\Emotion\\Die_Siedler3.csv not in games or not a directory\n",
      "WARNING: C:\\Uni\\dhcv\\output\\Location\\Die_Siedler3 contains files\n",
      "Output folder is ok.\n",
      "Processing Die_Siedler3: 19.35% -- 0hrs 0min remaining.[('siedler_frame_0.jpg', 0.1, 'indoor', 0.1310314, 'elevator/door', 0.120459005, 'museum/indoor', 0.05196093, 'science_museum', 0.031893235, 'clean_room', 0.022496004, 'playroom'), ('siedler_frame_30.jpg', 0.2, 'indoor', 0.09688987, 'amusement_arcade', 0.030483766, 'water_park', 0.02766633, 'recreation_room', 0.027316092, 'home_theater', 0.02416497, 'ball_pit'), ('siedler_frame_60.jpg', 0.6, 'outdoor', 0.035684552, 'amusement_arcade', 0.025850926, 'gas_station', 0.025004374, 'japanese_garden', 0.024813859, 'underwater/ocean_deep', 0.022955393, 'pet_shop'), ('siedler_frame_90.jpg', 0.3, 'indoor', 0.28292602, 'amusement_arcade', 0.09744652, 'gas_station', 0.07897822, 'server_room', 0.046373807, 'recreation_room', 0.03519498, 'hardware_store'), ('siedler_frame_120.jpg', 0.2, 'indoor', 0.26911548, 'amusement_arcade', 0.105934195, 'gas_station', 0.09610453, 'server_room', 0.043288305, 'recreation_room', 0.035481513, 'hardware_store'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Diablo2: 25.81% -- 0hrs 0min remaining.[('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Elden_Ring: 38.71% -- 0hrs 1min remaining.[('Emma_Thompson,_2022.jpg', 0.1, 'indoor', 0.22308818, 'arena/performance', 0.19996847, 'stage/indoor', 0.15867248, 'beauty_salon', 0.055330265, 'television_studio', 0.04057878, 'nursing_home'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Half_Life2: 45.16% -- 0hrs 1min remaining.[('Emma_Thompson,_2022.jpg', 0.1, 'indoor', 0.22308818, 'arena/performance', 0.19996847, 'stage/indoor', 0.15867248, 'beauty_salon', 0.055330265, 'television_studio', 0.04057878, 'nursing_home'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Little_Nightmares: 58.06% -- 0hrs 1min remaining.[('Emma_Thompson,_2022.jpg', 0.1, 'indoor', 0.22308818, 'arena/performance', 0.19996847, 'stage/indoor', 0.15867248, 'beauty_salon', 0.055330265, 'television_studio', 0.04057878, 'nursing_home'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing NFSMW: 64.52% -- 0hrs 1min remaining.[('Emma_Thompson,_2022.jpg', 0.1, 'indoor', 0.22308818, 'arena/performance', 0.19996847, 'stage/indoor', 0.15867248, 'beauty_salon', 0.055330265, 'television_studio', 0.04057878, 'nursing_home'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Starcraft2: 90.32% -- 0hrs 0min remaining.[('starcraft2_frame_0.jpg', 0.5, 'outdoor', 0.21562158, 'raceway', 0.112052515, 'arena/performance', 0.09541059, 'highway', 0.055190038, 'gas_station', 0.02691716, 'home_theater'), ('starcraft2_frame_60.jpg', 0.5, 'outdoor', 0.20978923, 'raceway', 0.10164995, 'highway', 0.09439453, 'arena/performance', 0.05336008, 'gas_station', 0.032856576, 'home_theater'), ('starcraft2_frame_120.jpg', 0.5, 'outdoor', 0.21322477, 'raceway', 0.12380912, 'highway', 0.10608605, 'arena/performance', 0.050405074, 'gas_station', 0.02934533, 'home_theater'), ('starcraft2_frame_180.jpg', 0.5, 'outdoor', 0.19525456, 'raceway', 0.13374613, 'highway', 0.10460807, 'arena/performance', 0.05490249, 'gas_station', 0.029486932, 'home_theater'), ('starcraft2_frame_240.jpg', 0.6, 'outdoor', 0.2805941, 'arena/performance', 0.10428165, 'aquarium', 0.070082396, 'sky', 0.034396406, 'volcano', 0.03098679, 'underwater/ocean_deep'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n",
      "Processing Super_Mario_World: 96.77% -- 0hrs 0min remaining.[('Emma_Thompson,_2022.jpg', 0.1, 'indoor', 0.22308818, 'arena/performance', 0.19996847, 'stage/indoor', 0.15867248, 'beauty_salon', 0.055330265, 'television_studio', 0.04057878, 'nursing_home'), ('Thomas_Brodie-Sangster_by_Gage_Skidmore.jpg', 0.2, 'indoor', 0.70501673, 'beauty_salon', 0.072693415, 'chemistry_lab', 0.0604826, 'biology_laboratory', 0.023116851, 'conference_center', 0.015802147, 'veterinarians_office'), ('Trump.jpeg', 0.0, 'indoor', 0.72161067, 'legislative_chamber', 0.12383862, 'nursing_home', 0.048825383, 'conference_center', 0.014247153, 'elevator/door', 0.007997716, 'archive')]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdXUlEQVR4nO3df3TV9X348VcSyY3WEnWUBDCatq5YqwYKkkXXI66pOUcPHWdnZ9T2CIepnR7sEXPWCiuSOTdju4q0NS2rLdWznQ78MdxaGJZG0dNKD0cgZ9ipHSLCekyQ40xs7BKWfL5/9Nt4riTIjQnhTR6Pcz5/5JP3+973fZ/Pued57r3JLcqyLAsAgAQUj/UCAACOlXABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAklFwuDz99NMxb968mDp1ahQVFcVjjz32rnO2bt0aH//4xyOXy8V5550XDzzwwDCWCgCMdwWHS3d3d9TU1ERLS8sxjX/55Zfj6quvjiuuuCLa2tpi6dKlcf3118fjjz9e8GIBgPGt6L18yWJRUVFs2LAh5s+fP+SY2267LTZu3BjPPffcwLnPfOYz8cYbb8TmzZuHe9cAwDh0ymjfwbZt26K+vj7vXENDQyxdunTIOT09PdHT0zPwc39/f7z++uvxe7/3e1FUVDRaSwUARlCWZfHmm2/G1KlTo7h4ZD5WO+rh0t7eHhUVFXnnKioqoqurK37zm9/EqaeeesSc5ubmuOOOO0Z7aQDAcXDgwIE4++yzR+S2Rj1chmP58uXR2Ng48HNnZ2ecc845sf6LfxKn5SaM4crgbU/3XjDWS4A8B/btHeslQJ7Dh3vj0Q3/HO9///tH7DZHPVwqKyujo6Mj71xHR0dMnDhx0FdbIiJyuVzkcrkjzp+WmxDvKysdlXVCoXJFZWO9BMhTOsHzIyemkfyYx6j/H5e6urpobW3NO7dly5aoq6sb7bsGAE4yBYfLr3/962hra4u2traI+O2fO7e1tcX+/fsj4rdv8yxcuHBg/I033hh79+6NL33pS/HCCy/Et771rXjooYfi1ltvHZlHAACMGwWHy7PPPhszZ86MmTNnRkREY2NjzJw5M1auXBkREa+++upAxEREfPCDH4yNGzfGli1boqamJu6555747ne/Gw0NDSP0EACA8aLgz7jMnTs3jvavXwb7r7hz586NXbt2FXpXAAB5fFcRAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJGFa4tLS0RHV1dZSVlUVtbW1s3779qONXr14d06dPj1NPPTWqqqri1ltvjf/93/8d1oIBgPGr4HBZv359NDY2RlNTU+zcuTNqamqioaEhDh48OOj4H/zgB7Fs2bJoamqK559/Pr73ve/F+vXr46/+6q/e8+IBgPGl4HBZtWpV3HDDDbF48eK44IILYs2aNXHaaafF2rVrBx3/zDPPxGWXXRaf/exno7q6Oq688sq45ppr3vVVGgCAdyooXHp7e2PHjh1RX1//9g0UF0d9fX1s27Zt0DmXXnpp7NixYyBU9u7dG5s2bYqrrrpqyPvp6emJrq6uvAMA4JRCBh86dCj6+vqioqIi73xFRUW88MILg8757Gc/G4cOHYo//MM/jCzL4v/+7//ixhtvPOpbRc3NzXHHHXcUsjQAYBwY9b8q2rp1a9x1113xrW99K3bu3Bn/8i//Ehs3bow777xzyDnLly+Pzs7OgePAgQOjvUwAIAEFveIyadKkKCkpiY6OjrzzHR0dUVlZOeic22+/Pa699tq4/vrrIyLioosuiu7u7vj85z8fX/7yl6O4+Mh2yuVykcvlClkaADAOFPSKS2lpacyaNStaW1sHzvX390dra2vU1dUNOuett946Ik5KSkoiIiLLskLXCwCMYwW94hIR0djYGIsWLYrZs2fHnDlzYvXq1dHd3R2LFy+OiIiFCxfGtGnTorm5OSIi5s2bF6tWrYqZM2dGbW1t7NmzJ26//faYN2/eQMAAAByLgsNlwYIF8dprr8XKlSujvb09ZsyYEZs3bx74wO7+/fvzXmFZsWJFFBUVxYoVK+JXv/pVfOADH4h58+bF3/3d343cowAAxoWiLIH3a7q6uqK8vDx+uGJBvK+sdKyXAxER8UTPhWO9BMizf++esV4C5Ok93BvrHnowOjs7Y+LEiSNym76rCABIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAwrXFpaWqK6ujrKysqitrY2tm/fftTxb7zxRixZsiSmTJkSuVwuPvKRj8SmTZuGtWAAYPw6pdAJ69evj8bGxlizZk3U1tbG6tWro6GhIV588cWYPHnyEeN7e3vjU5/6VEyePDkeeeSRmDZtWrzyyitxxhlnjMT6AYBxpOBwWbVqVdxwww2xePHiiIhYs2ZNbNy4MdauXRvLli07YvzatWvj9ddfj2eeeSYmTJgQERHV1dXvbdUAwLhU0FtFvb29sWPHjqivr3/7BoqLo76+PrZt2zbonH/7t3+Lurq6WLJkSVRUVMSFF14Yd911V/T19Q15Pz09PdHV1ZV3AAAUFC6HDh2Kvr6+qKioyDtfUVER7e3tg87Zu3dvPPLII9HX1xebNm2K22+/Pe65557427/92yHvp7m5OcrLyweOqqqqQpYJAJykRv2vivr7+2Py5Mnxne98J2bNmhULFiyIL3/5y7FmzZoh5yxfvjw6OzsHjgMHDoz2MgGABBT0GZdJkyZFSUlJdHR05J3v6OiIysrKQedMmTIlJkyYECUlJQPnPvrRj0Z7e3v09vZGaWnpEXNyuVzkcrlClgYAjAMFveJSWloas2bNitbW1oFz/f390draGnV1dYPOueyyy2LPnj3R398/cO6Xv/xlTJkyZdBoAQAYSsFvFTU2Nsb9998fDz74YDz//PNx0003RXd398BfGS1cuDCWL18+MP6mm26K119/PW655Zb45S9/GRs3boy77rorlixZMnKPAgAYFwr+c+gFCxbEa6+9FitXroz29vaYMWNGbN68eeADu/v374/i4rd7qKqqKh5//PG49dZb4+KLL45p06bFLbfcErfddtvIPQoAYFwoyrIsG+tFvJuurq4oLy+PH65YEO8r8/YSJ4Ynei4c6yVAnv1794z1EiBP7+HeWPfQg9HZ2RkTJ04ckdv0XUUAQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRjWOHS0tIS1dXVUVZWFrW1tbF9+/Zjmrdu3booKiqK+fPnD+duAYBxruBwWb9+fTQ2NkZTU1Ps3LkzampqoqGhIQ4ePHjUefv27Yu//Mu/jE984hPDXiwAML4VHC6rVq2KG264IRYvXhwXXHBBrFmzJk477bRYu3btkHP6+vric5/7XNxxxx3xoQ996F3vo6enJ7q6uvIOAICCwqW3tzd27NgR9fX1b99AcXHU19fHtm3bhpz3N3/zNzF58uS47rrrjul+mpubo7y8fOCoqqoqZJkAwEmqoHA5dOhQ9PX1RUVFRd75ioqKaG9vH3TOT3/60/je974X999//zHfz/Lly6Ozs3PgOHDgQCHLBABOUqeM5o2/+eabce2118b9998fkyZNOuZ5uVwucrncKK4MAEhRQeEyadKkKCkpiY6OjrzzHR0dUVlZecT4l156Kfbt2xfz5s0bONff3//bOz7llHjxxRfjwx/+8HDWDQCMQwW9VVRaWhqzZs2K1tbWgXP9/f3R2toadXV1R4w///zzY/fu3dHW1jZwfPrTn44rrrgi2trafHYFAChIwW8VNTY2xqJFi2L27NkxZ86cWL16dXR3d8fixYsjImLhwoUxbdq0aG5ujrKysrjwwgvz5p9xxhkREUecBwB4NwWHy4IFC+K1116LlStXRnt7e8yYMSM2b9488IHd/fv3R3Gxf8gLAIy8oizLsrFexLvp6uqK8vLy+OGKBfG+stKxXg5ERMQTPV415MSyf++esV4C5Ok93BvrHnowOjs7Y+LEiSNym14aAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcMKl5aWlqiuro6ysrKora2N7du3Dzn2/vvvj0984hNx5plnxplnnhn19fVHHQ8AMJSCw2X9+vXR2NgYTU1NsXPnzqipqYmGhoY4ePDgoOO3bt0a11xzTTz55JOxbdu2qKqqiiuvvDJ+9atfvefFAwDjS1GWZVkhE2pra+OSSy6J++67LyIi+vv7o6qqKr7whS/EsmXL3nV+X19fnHnmmXHffffFwoULBx3T09MTPT09Az93dXVFVVVV/HDFgnhfWWkhy4VR80TPhWO9BMizf++esV4C5Ok93BvrHnowOjs7Y+LEiSNymwW94tLb2xs7duyI+vr6t2+guDjq6+tj27Ztx3Qbb731Vhw+fDjOOuusIcc0NzdHeXn5wFFVVVXIMgGAk1RB4XLo0KHo6+uLioqKvPMVFRXR3t5+TLdx2223xdSpU/Pi552WL18enZ2dA8eBAwcKWSYAcJI65Xje2d133x3r1q2LrVu3RllZ2ZDjcrlc5HK547gyACAFBYXLpEmToqSkJDo6OvLOd3R0RGVl5VHnfu1rX4u77747fvKTn8TFF19c+EoBgHGvoLeKSktLY9asWdHa2jpwrr+/P1pbW6Ourm7IeV/96lfjzjvvjM2bN8fs2bOHv1oAYFwr+K2ixsbGWLRoUcyePTvmzJkTq1evju7u7li8eHFERCxcuDCmTZsWzc3NERHxla98JVauXBk/+MEPorq6euCzMKeffnqcfvrpI/hQAICTXcHhsmDBgnjttddi5cqV0d7eHjNmzIjNmzcPfGB3//79UVz89gs53/72t6O3tzf+9E//NO92mpqa4q//+q/f2+oBgHFlWB/Ovfnmm+Pmm28e9Hdbt27N+3nfvn3DuQsAgCP4riIAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIxrHBpaWmJ6urqKCsri9ra2ti+fftRxz/88MNx/vnnR1lZWVx00UWxadOmYS0WABjfCg6X9evXR2NjYzQ1NcXOnTujpqYmGhoa4uDBg4OOf+aZZ+Kaa66J6667Lnbt2hXz58+P+fPnx3PPPfeeFw8AjC9FWZZlhUyora2NSy65JO67776IiOjv74+qqqr4whe+EMuWLTti/IIFC6K7uzt+9KMfDZz7gz/4g5gxY0asWbNm0Pvo6emJnp6egZ87OzvjnHPOifVf/JM4LTehkOXCqHm694KxXgLkObBv71gvAfIcPtwbj27453jjjTeivLx8ZG40K0BPT09WUlKSbdiwIe/8woULs09/+tODzqmqqsruvffevHMrV67MLr744iHvp6mpKYsIh8PhcDgcJ8Hx0ksvFZIbR3VKFODQoUPR19cXFRUVeecrKirihRdeGHROe3v7oOPb29uHvJ/ly5dHY2PjwM9vvPFGnHvuubF///6RK7ZxqKurK6qqquLAgQMxceLEsV5O0uzlyLGXI8M+jhx7OXJ+947JWWedNWK3WVC4HC+5XC5yudwR58vLy11EI2DixIn2cYTYy5FjL0eGfRw59nLkFBeP3B8xF3RLkyZNipKSkujo6Mg739HREZWVlYPOqaysLGg8AMBQCgqX0tLSmDVrVrS2tg6c6+/vj9bW1qirqxt0Tl1dXd74iIgtW7YMOR4AYCgFv1XU2NgYixYtitmzZ8ecOXNi9erV0d3dHYsXL46IiIULF8a0adOiubk5IiJuueWWuPzyy+Oee+6Jq6++OtatWxfPPvtsfOc73znm+8zlctHU1DTo20ccO/s4cuzlyLGXI8M+jhx7OXJGYy8L/nPoiIj77rsv/v7v/z7a29tjxowZ8Y1vfCNqa2sjImLu3LlRXV0dDzzwwMD4hx9+OFasWBH79u2L3//934+vfvWrcdVVV43YgwAAxodhhQsAwFjwXUUAQDKECwCQDOECACRDuAAAyThhwqWlpSWqq6ujrKwsamtrY/v27Ucd//DDD8f5558fZWVlcdFFF8WmTZuO00pPbIXs4wMPPBBFRUV5R1lZ2XFc7Ynr6aefjnnz5sXUqVOjqKgoHnvssXeds3Xr1vj4xz8euVwuzjvvvLy/rBuvCt3HrVu3HnFNFhUVHfUrQsaD5ubmuOSSS+L9739/TJ48OebPnx8vvvjiu87zPHmk4eyl58rBffvb346LL7544D8M19XVxb//+78fdc5IXJMnRLisX78+Ghsbo6mpKXbu3Bk1NTXR0NAQBw8eHHT8M888E9dcc01cd911sWvXrpg/f37Mnz8/nnvuueO88hNLofsY8dt/af3qq68OHK+88spxXPGJq7u7O2pqaqKlpeWYxr/88stx9dVXxxVXXBFtbW2xdOnSuP766+Pxxx8f5ZWe2Ardx9958cUX867LyZMnj9IK0/DUU0/FkiVL4uc//3ls2bIlDh8+HFdeeWV0d3cPOcfz5OCGs5cRnisHc/bZZ8fdd98dO3bsiGeffTb+6I/+KP74j/84fvGLXww6fsSuyRH7usb3YM6cOdmSJUsGfu7r68umTp2aNTc3Dzr+z/7sz7Krr74671xtbW32F3/xF6O6zhNdofv4/e9/PysvLz9Oq0tXRBzxjejv9KUvfSn72Mc+lnduwYIFWUNDwyiuLC3Hso9PPvlkFhHZ//zP/xyXNaXq4MGDWURkTz311JBjPE8em2PZS8+Vx+7MM8/Mvvvd7w76u5G6Jsf8FZfe3t7YsWNH1NfXD5wrLi6O+vr62LZt26Bztm3bljc+IqKhoWHI8ePBcPYxIuLXv/51nHvuuVFVVXXUUuboXJMja8aMGTFlypT41Kc+FT/72c/GejknnM7OzoiIo37jrmvy2BzLXkZ4rnw3fX19sW7duuju7h7yK31G6poc83A5dOhQ9PX1RUVFRd75ioqKId/Xbm9vL2j8eDCcfZw+fXqsXbs2/vVf/zX+6Z/+Kfr7++PSSy+N//7v/z4eSz6pDHVNdnV1xW9+85sxWlV6pkyZEmvWrIlHH300Hn300aiqqoq5c+fGzp07x3ppJ4z+/v5YunRpXHbZZXHhhRcOOc7z5Ls71r30XDm03bt3x+mnnx65XC5uvPHG2LBhQ1xwwQWDjh2pa7Lg7yri5FFXV5dXxpdeeml89KMfjX/4h3+IO++8cwxXxng1ffr0mD59+sDPl156abz00ktx7733xj/+4z+O4cpOHEuWLInnnnsufvrTn471UpJ3rHvpuXJo06dPj7a2tujs7IxHHnkkFi1aFE899dSQ8TISxvwVl0mTJkVJSUl0dHTkne/o6IjKyspB51RWVhY0fjwYzj6+04QJE2LmzJmxZ8+e0VjiSW2oa3LixIlx6qmnjtGqTg5z5sxxTf5/N998c/zoRz+KJ598Ms4+++yjjvU8eXSF7OU7ea58W2lpaZx33nkxa9asaG5ujpqamvj6178+6NiRuibHPFxKS0tj1qxZ0draOnCuv78/Wltbh3yfrK6uLm98RMSWLVuGHD8eDGcf36mvry92794dU6ZMGa1lnrRck6Onra1t3F+TWZbFzTffHBs2bIgnnngiPvjBD77rHNfk4Iazl+/kuXJo/f390dPTM+jvRuyaHOYHh0fUunXrslwulz3wwAPZf/7nf2af//znszPOOCNrb2/PsizLrr322mzZsmUD43/2s59lp5xySva1r30te/7557OmpqZswoQJ2e7du8fqIZwQCt3HO+64I3v88cezl156KduxY0f2mc98JisrK8t+8YtfjNVDOGG8+eab2a5du7Jdu3ZlEZGtWrUq27VrV/bKK69kWZZly5Yty6699tqB8Xv37s1OO+207Itf/GL2/PPPZy0tLVlJSUm2efPmsXoIJ4RC9/Hee+/NHnvssey//uu/st27d2e33HJLVlxcnP3kJz8Zq4dwQrjpppuy8vLybOvWrdmrr746cLz11lsDYzxPHpvh7KXnysEtW7Yse+qpp7KXX345+4//+I9s2bJlWVFRUfbjH/84y7LRuyZPiHDJsiz75je/mZ1zzjlZaWlpNmfOnOznP//5wO8uv/zybNGiRXnjH3rooewjH/lIVlpamn3sYx/LNm7ceJxXfGIqZB+XLl06MLaioiK76qqrsp07d47Bqk88v/uz3Hcev9u/RYsWZZdffvkRc2bMmJGVlpZmH/rQh7Lvf//7x33dJ5pC9/ErX/lK9uEPfzgrKyvLzjrrrGzu3LnZE088MTaLP4EMtocRkXeNeZ48NsPZS8+Vg/vzP//z7Nxzz81KS0uzD3zgA9knP/nJgWjJstG7JouyLMsKe40GAGBsjPlnXAAAjpVwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZPw/rntXd2dYr3oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = Configuration()\n",
    "config.checkInputFolder()\n",
    "config.checkOutputFolder()\n",
    "\n",
    "reportCount = 2 #TODO change to 50\n",
    "count = 0\n",
    "end = config.getFileLength()\n",
    "startTime = time.time()\n",
    "\n",
    "for gameName in config.getGameNames():\n",
    "  ageGender = AgeGender(gameName, config.getOutputRoot())\n",
    "  brightnessAnalyzer = BrightnessAnalyzer(gameName, config.getOutputRoot())\n",
    "  dominantColor = DominantColor( gameName, config.getOutputRoot())\n",
    "  averageColor = AverageColor(gameName, config.getOutputRoot())\n",
    "  emotionDetection = EmotionDetection(gameName, config.getOutputRoot())\n",
    "  locationDetection = LocationDetection(gameName, config.getOutputRoot())\n",
    "\n",
    "  framesList = os.listdir(f\"{config.getInputRoot()}{gameName}\\\\\")\n",
    "  framesList = natsorted(framesList, alg=ns.PATH | ns.IGNORECASE)\n",
    "\n",
    "  for frameName in framesList:\n",
    "    count += 1\n",
    "\n",
    "    if not frameName.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n",
    "      continue\n",
    "    \n",
    "    frameData = cv2.imread(f\"{config.getInputRoot()}{gameName}\\\\{frameName}\")\n",
    "    \n",
    "    ageGender.handleNextImage(frameName, frameData)\n",
    "    brightnessAnalyzer.handleNextImage(frameName, frameData)\n",
    "    dominantColor.handleNextImage(frameName, frameData)\n",
    "    averageColor.handleNextImage(frameName, frameData)\n",
    "    emotionDetection.handleNextImage(frameName, frameData)\n",
    "    locationDetection.handleNextImage(frameName, frameData)\n",
    "  \n",
    "    if count % reportCount == 0:\n",
    "      reportProgress(count, end, gameName, startTime)\n",
    "    \n",
    "  #save data as csv\n",
    "  ageGender.dataToCSV()\n",
    "  brightnessAnalyzer.dataToCSV()\n",
    "  dominantColor.dataToCSV()\n",
    "  averageColor.dataToCSV()\n",
    "  emotionDetection.dataToCSV()\n",
    "  locationDetection.dataToCSV()\n",
    "\n",
    "  #generate color bars\n",
    "  dominantColor.generateColorBars()\n",
    "  averageColor.generateColorBars()\n",
    "\n",
    "  #generate greyscale graph\n",
    "  brightnessAnalyzer.generateGreyScaleGraph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6540d84677c43a09ba77dca21a04ef847cd39b5846de4b170515afa4945c7b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
